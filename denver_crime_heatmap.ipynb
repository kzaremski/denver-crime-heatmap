{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denver Crime Heatmap Notebook\n",
    "CS 3120 Machine Learning Term Project - Konstantin Zaremski\n",
    "\n",
    "---\n",
    "\n",
    "This comprehensive notebook covers my project from ideation and planning, to exploratory data analysis (EDA), and final implementation.\n",
    "\n",
    "> ### Project Proposal\n",
    "> ##### Introduction & Description\n",
    "> After my car was vandalized in Denver earlier this October, I began ruminating on what makes an area “safe”. Eventually I came upon the Denver Public Crime Map which shows the 1000 most recent incidents on a map. This got me interested in the possibility of using this data in a predictive capacity. I am going to build a Denver crime prediction or likelihood map app, that will predict the likelihood of crime overall, predict the most likely crimes to be committed for different areas, and then present this as a heatmap visualization to the user.\n",
    "> \n",
    "> ##### Dataset\n",
    "> The source dataset for the public crime map is provided by Denver and contains 394,475 data points sourced from the FBI’s NIBRS database. After stripping off useless columns such as database keys and precinct numbers, the usable columns are the date and time of occurrence, type and category of crime, and longitude and latitude. Crimes do not happen because of a longitude and latitude value, so I am enriching the original dataset by adding additional features by querying each data point against Open Street Map data for land use, proximity to residential or main roads, building types, and amenities such as ATMs or RTD stations.\n",
    "> \n",
    "> ##### Model\n",
    "> I will be training two models to make predictions for my app: one model to enable the prediction of the total amount of crimes in an area given input features, and another model to perform multiclass classification to predict what type of crime is most likely to be committed in an area given input features. Since the input data and resulting crime or number of crimes is known and labeled, supervised learning models are best suited for this data. I will be using SciKit Learn’s HistGradientBoostingClassifier to predict crime type and HistGradientBoostingRegressor to predict crime volume. I am electing to use gradient boosting over decision trees or other models since it has a lower bias and should be more sensitive to different crime patterns.\n",
    "> \n",
    "> ##### App Functionality\n",
    "> The web app will be a simple map interface with a color heatmap overlay based on the underlying model’s crime predictions. The user will have options for a time delta, where they can view the heatmap/predictions for the current time plus or minus up to 48 hours. The user will have a way to toggle between seeing a multi-color heatmap for the types of crimes that are predicted, a single-color heatmap for the likelihood or predicted frequency of crime, and a heatmap that combines both, with areas having a lower predicted likelihood or frequency of crime being denoted by a more transparent version of the color representing the crime type for that area.\n",
    "> \n",
    "> ##### Technical Implementation\n",
    "> Since the app does not have user accounts, the backend can be implemented as a simple Flask app with an API endpoint to retrieve the heatmap overlay based on the map area the client says the user is currently viewing. Predictions will be stored in an SQLite database where they can be quickly retrieved to generate a heatmap at view time. The frontend will be implemented using simple HTML, CSS, and vanilla JavaScript to enable interactions. The map itself will be rendered using the Leaflet JavaScript map library/project.\n",
    "> \n",
    "> ##### Feasibility\n",
    "> Since the app itself is a visualization with only a few buttons/interactions, and no user accounts or user data collection, it will be simple to implement, which will allow for more time to be spent on tuning the models and finding the optimal way to slice the map or bin data.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis & Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Importing required modules and libraries for EDA, etc. See `requirements_eda.txt` for a full list of requirements to install into the environment using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import math\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>OFFENSE_ID</th>\n",
       "      <th>OFFENSE_CODE</th>\n",
       "      <th>OFFENSE_CODE_EXTENSION</th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>OFFENSE_CATEGORY_ID</th>\n",
       "      <th>FIRST_OCCURRENCE_DATE</th>\n",
       "      <th>LAST_OCCURRENCE_DATE</th>\n",
       "      <th>REPORTED_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "      <th>DISTRICT_ID</th>\n",
       "      <th>PRECINCT_ID</th>\n",
       "      <th>NEIGHBORHOOD_ID</th>\n",
       "      <th>IS_CRIME</th>\n",
       "      <th>IS_TRAFFIC</th>\n",
       "      <th>VICTIM_COUNT</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2020467360</td>\n",
       "      <td>2020467360299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>8/2/2020 10:43:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/2/2020 10:43:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.024597</td>\n",
       "      <td>39.689751</td>\n",
       "      <td>4</td>\n",
       "      <td>422</td>\n",
       "      <td>ruby-hill</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.133789e+06</td>\n",
       "      <td>1.676471e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>20196003434</td>\n",
       "      <td>20196003434299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>4/20/2019 7:30:00 AM</td>\n",
       "      <td>4/20/2019 8:45:00 AM</td>\n",
       "      <td>4/20/2019 6:30:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.987348</td>\n",
       "      <td>39.714316</td>\n",
       "      <td>3</td>\n",
       "      <td>311</td>\n",
       "      <td>speer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.144221e+06</td>\n",
       "      <td>1.685476e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>2020123049</td>\n",
       "      <td>2020123049299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>2/25/2020 11:30:00 PM</td>\n",
       "      <td>2/26/2020 6:45:00 AM</td>\n",
       "      <td>2/26/2020 7:30:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.988098</td>\n",
       "      <td>39.764528</td>\n",
       "      <td>6</td>\n",
       "      <td>612</td>\n",
       "      <td>five-points</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.143907e+06</td>\n",
       "      <td>1.703765e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>2021621685</td>\n",
       "      <td>2021621685299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>11/1/2021 6:20:00 AM</td>\n",
       "      <td>11/1/2021 6:30:00 AM</td>\n",
       "      <td>11/1/2021 10:15:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.004665</td>\n",
       "      <td>39.739669</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>lincoln-park</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.139299e+06</td>\n",
       "      <td>1.694684e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>2020289138</td>\n",
       "      <td>2020289138299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>5/9/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/11/2020 12:05:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.830661</td>\n",
       "      <td>39.795281</td>\n",
       "      <td>5</td>\n",
       "      <td>521</td>\n",
       "      <td>montbello</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.188083e+06</td>\n",
       "      <td>1.715255e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  INCIDENT_ID         OFFENSE_ID  OFFENSE_CODE  \\\n",
       "0     20000   2020467360   2020467360299901          2999   \n",
       "1     20001  20196003434  20196003434299901          2999   \n",
       "2     20002   2020123049   2020123049299901          2999   \n",
       "3     20003   2021621685   2021621685299901          2999   \n",
       "4     20004   2020289138   2020289138299901          2999   \n",
       "\n",
       "   OFFENSE_CODE_EXTENSION            OFFENSE_TYPE_ID OFFENSE_CATEGORY_ID  \\\n",
       "0                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "1                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "2                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "3                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "4                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "\n",
       "   FIRST_OCCURRENCE_DATE  LAST_OCCURRENCE_DATE          REPORTED_DATE  ...  \\\n",
       "0   8/2/2020 10:43:00 PM                   NaN   8/2/2020 10:43:00 PM  ...   \n",
       "1   4/20/2019 7:30:00 AM  4/20/2019 8:45:00 AM   4/20/2019 6:30:00 PM  ...   \n",
       "2  2/25/2020 11:30:00 PM  2/26/2020 6:45:00 AM   2/26/2020 7:30:00 AM  ...   \n",
       "3   11/1/2021 6:20:00 AM  11/1/2021 6:30:00 AM  11/1/2021 10:15:00 AM  ...   \n",
       "4   5/9/2020 12:00:00 PM                   NaN  5/11/2020 12:05:00 PM  ...   \n",
       "\n",
       "      GEO_LON    GEO_LAT  DISTRICT_ID  PRECINCT_ID  NEIGHBORHOOD_ID IS_CRIME  \\\n",
       "0 -105.024597  39.689751            4          422        ruby-hill        1   \n",
       "1 -104.987348  39.714316            3          311            speer        1   \n",
       "2 -104.988098  39.764528            6          612      five-points        1   \n",
       "3 -105.004665  39.739669            1          123     lincoln-park        1   \n",
       "4 -104.830661  39.795281            5          521        montbello        1   \n",
       "\n",
       "   IS_TRAFFIC VICTIM_COUNT             x             y  \n",
       "0           0            1  3.133789e+06  1.676471e+06  \n",
       "1           0            1  3.144221e+06  1.685476e+06  \n",
       "2           0            1  3.143907e+06  1.703765e+06  \n",
       "3           0            1  3.139299e+06  1.694684e+06  \n",
       "4           0            1  3.188083e+06  1.715255e+06  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 394736 records!\n"
     ]
    }
   ],
   "source": [
    "# Find all crime data CSV files matching the naming pattern\n",
    "csv_files = glob.glob(\"data/crime_split_*.csv\")\n",
    "\n",
    "# Read in all of the files and create Pandas dataframes from them\n",
    "split_dfs = [pd.read_csv(f) for f in csv_files]\n",
    "\n",
    "# Concatenate all the dataframes into a single one\n",
    "df = pd.concat(split_dfs, ignore_index=True)\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "original_dataframe_shape = df.shape\n",
    "print(f'Loaded {original_dataframe_shape[0]} records!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Analysis\n",
    "The next thing to do is determine which columns will be useful for predictions and which columns need to be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime Dataset Columns:\n",
      " - OBJECTID\n",
      " - INCIDENT_ID\n",
      " - OFFENSE_ID\n",
      " - OFFENSE_CODE\n",
      " - OFFENSE_CODE_EXTENSION\n",
      " - OFFENSE_TYPE_ID\n",
      " - OFFENSE_CATEGORY_ID\n",
      " - FIRST_OCCURRENCE_DATE\n",
      " - LAST_OCCURRENCE_DATE\n",
      " - REPORTED_DATE\n",
      " - INCIDENT_ADDRESS\n",
      " - GEO_X\n",
      " - GEO_Y\n",
      " - GEO_LON\n",
      " - GEO_LAT\n",
      " - DISTRICT_ID\n",
      " - PRECINCT_ID\n",
      " - NEIGHBORHOOD_ID\n",
      " - IS_CRIME\n",
      " - IS_TRAFFIC\n",
      " - VICTIM_COUNT\n",
      " - x\n",
      " - y\n"
     ]
    }
   ],
   "source": [
    "print(\"Crime Dataset Columns:\")\n",
    "for column in df.columns:\n",
    "    print(f\" - {column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Decisions\n",
    "| Column ID                 | Decision  | Explanation                                                                                        |\n",
    "|---------------------------|-----------|----------------------------------------------------------------------------------------------------|\n",
    "| `OBJECTID`                | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `INCIDENT_ID`             | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_ID`              | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_CODE`            | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_CODE_EXTENSION`  | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_TYPE_ID`         | Kept      | This is part of the output (y-values). We will keep this column and it will be the subject of prediction by the classification model. |\n",
    "| `OFFENSE_CATEGORY_ID`     | Discarded | This is part of the output (y-values). This will be discarded in  |\n",
    "| `FIRST_OCCURRENCE_DATE`   | Kept      | Timestamp of the event, this will be kept and used for predictions made based on the time of day. |\n",
    "| `LAST_OCCURRENCE_DATE`    | Discarded | Undefined for many rows. We will discard this timestamp and rely on `FIRST_OCCURRENCE_DATE` instead.                              |\n",
    "| `REPORTED_DATE`           | Discarded | This is part of the output (y-values). Report time delta from occurrence varies incident to incident. No predictive value.                             |\n",
    "| `INCIDENT_ADDRESS`        | Discarded | Although address is useful, this column is not standardized with entries like \"2400 block\" rather than exact addresses in some cases. |\n",
    "| `GEO_X`                   | Discarded | Related to the mapping platform the data was posted on. No predictive value.                    |\n",
    "| `GEO_Y`                   | Discarded | Related to the mapping platform the data was posted on. No predictive value.                    |\n",
    "| `GEO_LON`                 | Kept      | Location of the crime, this will be kept and used to make predictions based on location. |\n",
    "| `GEO_LAT`                 | Kept      | Location of the crime, this will be kept and used to make predictions based on location. |\n",
    "| `DISTRICT_ID`             | Discarded | This is part of the output (y-values) and we have no way of querying. No predictive value.                    |\n",
    "| `PRECINCT_ID`             | Discarded | This is part of the output (y-values) and we have no way of querying. No predictive value.                             |\n",
    "| `NEIGHBORHOOD_ID`         | Discarded | Although neighborhood is useful, as some are \"rougher\" than others, we don't have a standard way of querying.                             |\n",
    "| `IS_CRIME`                | Discarded | This is part of the output (y-values). No predictive value.                             |\n",
    "| `IS_TRAFFIC`              | Discarded | This is part of the output (y-values). No predictive value.                             |\n",
    "| `VICTIM_COUNT`            | Discarded | This is part of the output (y-values). No predictive value.                             |\n",
    "| `x`                       | Discarded | Related to the mapping platform the data was posted on. No predictive value.                     |\n",
    "| `y`                       | Discarded | Related to the mapping platform the data was posted on. No predictive value.                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>FIRST_OCCURRENCE_DATE</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113081</th>\n",
       "      <td>police-false-information</td>\n",
       "      <td>2/25/2020 1:23:00 PM</td>\n",
       "      <td>-104.961788</td>\n",
       "      <td>39.682689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180334</th>\n",
       "      <td>theft-shoplift</td>\n",
       "      <td>3/23/2019 2:00:00 PM</td>\n",
       "      <td>-104.939123</td>\n",
       "      <td>39.667547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272876</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>12/8/2019 8:00:00 PM</td>\n",
       "      <td>-104.965060</td>\n",
       "      <td>39.754979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12242</th>\n",
       "      <td>theft-items-from-vehicle</td>\n",
       "      <td>6/6/2022 7:00:00 AM</td>\n",
       "      <td>-104.676993</td>\n",
       "      <td>39.844158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91358</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>4/5/2023 6:30:00 AM</td>\n",
       "      <td>-104.991513</td>\n",
       "      <td>39.747421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109103</th>\n",
       "      <td>burglary-residence-by-force</td>\n",
       "      <td>4/12/2020 12:00:00 PM</td>\n",
       "      <td>-104.974962</td>\n",
       "      <td>39.735996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199263</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>6/1/2022 11:35:00 PM</td>\n",
       "      <td>-105.001101</td>\n",
       "      <td>39.732382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158894</th>\n",
       "      <td>false-imprisonment</td>\n",
       "      <td>6/10/2021 7:30:00 PM</td>\n",
       "      <td>-104.832142</td>\n",
       "      <td>39.797782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178178</th>\n",
       "      <td>burglary-business-no-force</td>\n",
       "      <td>4/18/2020 12:43:00 AM</td>\n",
       "      <td>-104.980569</td>\n",
       "      <td>39.688525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207203</th>\n",
       "      <td>theft-items-from-vehicle</td>\n",
       "      <td>7/11/2024 8:00:00 AM</td>\n",
       "      <td>-104.991195</td>\n",
       "      <td>39.752503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10462</th>\n",
       "      <td>theft-items-from-vehicle</td>\n",
       "      <td>10/4/2021 5:30:00 AM</td>\n",
       "      <td>-104.942352</td>\n",
       "      <td>39.709997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231500</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>3/23/2021 8:30:00 PM</td>\n",
       "      <td>-104.861964</td>\n",
       "      <td>39.658404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173069</th>\n",
       "      <td>theft-parts-from-vehicle</td>\n",
       "      <td>6/25/2021 7:15:00 AM</td>\n",
       "      <td>-104.927049</td>\n",
       "      <td>39.698895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236243</th>\n",
       "      <td>assault-simple</td>\n",
       "      <td>12/7/2021 6:00:00 AM</td>\n",
       "      <td>-105.005465</td>\n",
       "      <td>39.739796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200595</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>8/14/2022 12:00:00 PM</td>\n",
       "      <td>-104.755943</td>\n",
       "      <td>39.793282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128805</th>\n",
       "      <td>homicide-other</td>\n",
       "      <td>9/27/2024 10:33:00 PM</td>\n",
       "      <td>-104.941359</td>\n",
       "      <td>39.791834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344023</th>\n",
       "      <td>criminal-trespassing</td>\n",
       "      <td>10/31/2022 2:19:00 AM</td>\n",
       "      <td>-104.941688</td>\n",
       "      <td>39.680871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310559</th>\n",
       "      <td>burglary-residence-no-force</td>\n",
       "      <td>11/25/2022 8:02:00 AM</td>\n",
       "      <td>-105.052225</td>\n",
       "      <td>39.739791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80678</th>\n",
       "      <td>theft-parts-from-vehicle</td>\n",
       "      <td>7/31/2021 11:00:00 PM</td>\n",
       "      <td>-104.982744</td>\n",
       "      <td>39.777662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116573</th>\n",
       "      <td>violation-of-restraining-order</td>\n",
       "      <td>9/27/2021 1:00:00 PM</td>\n",
       "      <td>-104.941065</td>\n",
       "      <td>39.694405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       OFFENSE_TYPE_ID  FIRST_OCCURRENCE_DATE     GEO_LON  \\\n",
       "113081        police-false-information   2/25/2020 1:23:00 PM -104.961788   \n",
       "180334                  theft-shoplift   3/23/2019 2:00:00 PM -104.939123   \n",
       "272876          theft-of-motor-vehicle   12/8/2019 8:00:00 PM -104.965060   \n",
       "12242         theft-items-from-vehicle    6/6/2022 7:00:00 AM -104.676993   \n",
       "91358           theft-of-motor-vehicle    4/5/2023 6:30:00 AM -104.991513   \n",
       "109103     burglary-residence-by-force  4/12/2020 12:00:00 PM -104.974962   \n",
       "199263          theft-of-motor-vehicle   6/1/2022 11:35:00 PM -105.001101   \n",
       "158894              false-imprisonment   6/10/2021 7:30:00 PM -104.832142   \n",
       "178178      burglary-business-no-force  4/18/2020 12:43:00 AM -104.980569   \n",
       "207203        theft-items-from-vehicle   7/11/2024 8:00:00 AM -104.991195   \n",
       "10462         theft-items-from-vehicle   10/4/2021 5:30:00 AM -104.942352   \n",
       "231500          theft-of-motor-vehicle   3/23/2021 8:30:00 PM -104.861964   \n",
       "173069        theft-parts-from-vehicle   6/25/2021 7:15:00 AM -104.927049   \n",
       "236243                  assault-simple   12/7/2021 6:00:00 AM -105.005465   \n",
       "200595          theft-of-motor-vehicle  8/14/2022 12:00:00 PM -104.755943   \n",
       "128805                  homicide-other  9/27/2024 10:33:00 PM -104.941359   \n",
       "344023            criminal-trespassing  10/31/2022 2:19:00 AM -104.941688   \n",
       "310559     burglary-residence-no-force  11/25/2022 8:02:00 AM -105.052225   \n",
       "80678         theft-parts-from-vehicle  7/31/2021 11:00:00 PM -104.982744   \n",
       "116573  violation-of-restraining-order   9/27/2021 1:00:00 PM -104.941065   \n",
       "\n",
       "          GEO_LAT  \n",
       "113081  39.682689  \n",
       "180334  39.667547  \n",
       "272876  39.754979  \n",
       "12242   39.844158  \n",
       "91358   39.747421  \n",
       "109103  39.735996  \n",
       "199263  39.732382  \n",
       "158894  39.797782  \n",
       "178178  39.688525  \n",
       "207203  39.752503  \n",
       "10462   39.709997  \n",
       "231500  39.658404  \n",
       "173069  39.698895  \n",
       "236243  39.739796  \n",
       "200595  39.793282  \n",
       "128805  39.791834  \n",
       "344023  39.680871  \n",
       "310559  39.739791  \n",
       "80678   39.777662  \n",
       "116573  39.694405  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "very_first_dataframe = df.copy()\n",
    "\n",
    "# Keep only the columns that we want\n",
    "df = df[['OFFENSE_TYPE_ID','FIRST_OCCURRENCE_DATE','GEO_LON','GEO_LAT']]\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Binning\n",
    "In this analysis, time binning is used to capture the cyclical and seasonal patterns inherent in criminal behavior. Crime often follows temporal trends—certain types of incidents may be more likely to occur at specific times of day, days of the week, or during particular seasons. For example, incidents related to nightlife might peak during late evening hours, while other crimes may correlate with daily commuter traffic or specific days like weekends. By extracting temporal features like `YEAR`, `DAY_OF_YEAR`, `DAY_OF_WEEK`, and a continuous `TIME` (floating-point hour), we enable the model to identify these patterns and trends. This granular binning enhances the predictive power of the model, allowing it to detect not only broad time-based patterns but also more subtle nuances in how crime evolves throughout the day, week, and year.\n",
    "\n",
    "#### Temporal Features Breakdown\n",
    "* `YEAR`: Provides a clear yearly context, which can be crucial for identifying long-term trends or annual shifts in patterns.\n",
    "* `TIME` (floating point): Offers a precise measure of the time of day, allowing models to pick up on subtle temporal shifts within a 24-hour cycle.\n",
    "* `DAY_OF_YEAR`: Captures the day within the year, useful for identifying seasonal patterns or trends that recur annually.\n",
    "* `DAY_OF_WEEK`: Encodes weekly cycles, helping the model detect patterns associated with specific weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>HOUR_COS</th>\n",
       "      <th>HOUR_SIN</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339722</th>\n",
       "      <td>fraud-by-telephone</td>\n",
       "      <td>-104.887304</td>\n",
       "      <td>39.747042</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310581</th>\n",
       "      <td>theft-parts-from-vehicle</td>\n",
       "      <td>-104.927623</td>\n",
       "      <td>39.675576</td>\n",
       "      <td>2022</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>330</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323035</th>\n",
       "      <td>theft-bicycle</td>\n",
       "      <td>-104.977265</td>\n",
       "      <td>39.731304</td>\n",
       "      <td>2020</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>305</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355732</th>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>-104.998509</td>\n",
       "      <td>39.732305</td>\n",
       "      <td>2022</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>357</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51393</th>\n",
       "      <td>theft-items-from-vehicle</td>\n",
       "      <td>-105.038749</td>\n",
       "      <td>39.686763</td>\n",
       "      <td>2020</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>170</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  OFFENSE_TYPE_ID     GEO_LON    GEO_LAT  YEAR      HOUR_COS  \\\n",
       "339722         fraud-by-telephone -104.887304  39.747042  2022  8.660254e-01   \n",
       "310581   theft-parts-from-vehicle -104.927623  39.675576  2022 -2.588190e-01   \n",
       "323035              theft-bicycle -104.977265  39.731304  2020 -9.659258e-01   \n",
       "355732  criminal-mischief-mtr-veh -104.998509  39.732305  2022 -1.836970e-16   \n",
       "51393    theft-items-from-vehicle -105.038749  39.686763  2020 -1.836970e-16   \n",
       "\n",
       "        HOUR_SIN  DAY_OF_YEAR  DAY_OF_WEEK  \n",
       "339722  0.500000           68            2  \n",
       "310581 -0.965926          330            5  \n",
       "323035  0.258819          305            5  \n",
       "355732 -1.000000          357            4  \n",
       "51393  -1.000000          170            3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert FIRST_OCCURRENCE_DATE to Pandas date time format\n",
    "df['FIRST_OCCURRENCE_DATE'] = pd.to_datetime(df['FIRST_OCCURRENCE_DATE'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# Extract date and time components\n",
    "df['YEAR'] = df['FIRST_OCCURRENCE_DATE'].dt.year\n",
    "# df['MONTH'] = df['FIRST_OCCURRENCE_DATE'].dt.month -- Removed in favor of DAY_OF_YEAR\n",
    "# df['DAY_OF_MONTH'] = df['FIRST_OCCURRENCE_DATE'].dt.day -- Removed in favor of DAY_OF_YEAR\n",
    "# df['TIME'] = (\n",
    "#     df['FIRST_OCCURRENCE_DATE'].dt.hour + \n",
    "#     df['FIRST_OCCURRENCE_DATE'].dt.minute / 60 + \n",
    "#     df['FIRST_OCCURRENCE_DATE'].dt.second / 3600\n",
    "# ) -- No longer doing floating point hour\n",
    "# df['HOUR'] = df['FIRST_OCCURRENCE_DATE'].dt.hour\n",
    "df['HOUR_COS'] = np.cos(2 * np.pi * df['FIRST_OCCURRENCE_DATE'].dt.hour / 24) # Learned that some models interpret hour 0 and \n",
    "df['HOUR_SIN'] = np.sin(2 * np.pi * df['FIRST_OCCURRENCE_DATE'].dt.hour / 24) #   hour 23 as far apart even though they are together. Sin/Cos make continuous.\n",
    "df['DAY_OF_YEAR'] = df['FIRST_OCCURRENCE_DATE'].dt.dayofyear\n",
    "df['DAY_OF_WEEK'] = df['FIRST_OCCURRENCE_DATE'].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Finally, dropping the FIRST_OCCURRENCE_DATE column\n",
    "df.drop(columns=['FIRST_OCCURRENCE_DATE'], inplace=True)\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Slicing & Binning \n",
    "In this step, we convert latitude and longitude into a 15-meter by 15-meter grid system using a projected coordinate system (UTM). This method ensures that each crime location is assigned to a unique, precise grid cell, facilitating accurate spatial analysis.\n",
    "\n",
    "See <https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system>\n",
    "\n",
    "#### Why This is Better Than Using Raw Latitude and Longitude\n",
    "\n",
    "Using UTM coordinates overcomes the limitations of raw latitude and longitude, which vary in distance depending on location. UTM coordinates provide uniform distance measurements in meters, improving precision and making it easier to define consistent grid cells. This approach also simplifies spatial analysis by grouping data into fixed-size cells, making patterns like crime hotspots easier to identify and computationally more efficient to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size before removal: 394736 items\n",
      "Dataframe size after removal: 394475 items\n",
      "--> 261 items removed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>HOUR_COS</th>\n",
       "      <th>HOUR_SIN</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>X_BLOCK</th>\n",
       "      <th>Y_BLOCK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367367</th>\n",
       "      <td>assault-simple</td>\n",
       "      <td>2023</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>292</td>\n",
       "      <td>3</td>\n",
       "      <td>33404</td>\n",
       "      <td>293445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315042</th>\n",
       "      <td>theft-other</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>33030</td>\n",
       "      <td>293210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277464</th>\n",
       "      <td>theft-shoplift</td>\n",
       "      <td>2024</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>33676</td>\n",
       "      <td>292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328868</th>\n",
       "      <td>theft-other</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>35192</td>\n",
       "      <td>294091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211997</th>\n",
       "      <td>criminal-trespassing</td>\n",
       "      <td>2024</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>33446</td>\n",
       "      <td>293255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             OFFENSE_TYPE_ID  YEAR      HOUR_COS  HOUR_SIN  DAY_OF_YEAR  \\\n",
       "367367        assault-simple  2023 -9.659258e-01 -0.258819          292   \n",
       "315042           theft-other  2019  1.000000e+00  0.000000          147   \n",
       "277464        theft-shoplift  2024 -8.660254e-01  0.500000           93   \n",
       "328868           theft-other  2020  6.123234e-17  1.000000           27   \n",
       "211997  criminal-trespassing  2024 -5.000000e-01  0.866025          220   \n",
       "\n",
       "        DAY_OF_WEEK  X_BLOCK  Y_BLOCK  \n",
       "367367            3    33404   293445  \n",
       "315042            0    33030   293210  \n",
       "277464            1    33676   292700  \n",
       "328868            0    35192   294091  \n",
       "211997            2    33446   293255  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GRID_SIZE = 15 # 15m x 15m grid cells\n",
    "\n",
    "# Initialize UTM projection (assuming UTM Zone 13N for Denver)\n",
    "#   https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system\n",
    "#   https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system#/media/File:Universal_Transverse_Mercator_zones.svg\n",
    "utm_proj = pyproj.Proj(proj=\"utm\", zone=13, datum=\"WGS84\")\n",
    "\n",
    "def get_grid_block(lat, lon):\n",
    "    try:\n",
    "        # Convert latitude and longitude to UTM coordinates (X, Y)\n",
    "        x, y = utm_proj(lon, lat)  # Correct order: lon, lat\n",
    "        \n",
    "        # Calculate the X and Y blocks\n",
    "        x_block = int(x // GRID_SIZE)\n",
    "        y_block = int(y // GRID_SIZE)\n",
    "        \n",
    "        return x_block, y_block\n",
    "    except:\n",
    "        # If there is an issue parsing, return -1\n",
    "        return -1, -1\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['X_BLOCK', 'Y_BLOCK']] = df.apply(lambda row: get_grid_block(row['GEO_LAT'], row['GEO_LON']), axis=1, result_type='expand')\n",
    "\n",
    "# Drop rows where X_BLOCK or Y_BLOCK is -1\n",
    "df = df[(df['X_BLOCK'] != -1) & (df['Y_BLOCK'] != -1)]\n",
    "\n",
    "# Note change in size\n",
    "post_null_geo_block_removal_dataframe_shape = df.shape\n",
    "print(f'Dataframe size before removal: {original_dataframe_shape[0]} items')\n",
    "print(f'Dataframe size after removal: {post_null_geo_block_removal_dataframe_shape[0]} items')\n",
    "print(f'--> {original_dataframe_shape[0] - post_null_geo_block_removal_dataframe_shape[0]} items removed!')\n",
    "\n",
    "# Finally, dropping the GEO_LAT and GEO_LON columns since we have replaced them with X_BLOCK and Y_BLOCK\n",
    "df.drop(columns=['GEO_LAT'], inplace=True)\n",
    "df.drop(columns=['GEO_LON'], inplace=True)\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are processing the geographical data to assign each crime incident to a specific grid cell based on its latitude and longitude. We achieve this by converting the coordinates to UTM projection, which provides more accurate distance-based calculations than traditional latitude and longitude. For each point, we calculate the corresponding grid cell by dividing the UTM coordinates by the grid size (15 meters) and then storing the results as `X_BLOCK` and `Y_BLOCK`.\n",
    "\n",
    "However, if any coordinates cannot be processed correctly (due to projection issues or invalid data), we assign -1 as a placeholder. After applying this transformation, we remove any rows where either the `X_BLOCK` or `Y_BLOCK` is -1, indicating invalid grid assignments. The sizes of the DataFrame before and after this removal are printed to highlight the impact of cleaning the data. This step ensures that only valid data points are included for further analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Location Outliers\n",
    "When exporting the data as a CSV file, it can be observed that some of the rows have really low or high X-block values. These are likely location mis-inputs.\n",
    "\n",
    "We can drop these rows by calculating the interquartile range range for the `X_BLOCK` and `Y_BLOCK` columns and dropping the rows that are outliers.\n",
    "\n",
    "What I have done below is not the interquartile range. I only want to drop extreme outliers, so I dropped the values that fall outside the middle 98% of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before location outlier removal: 394475 records.\n",
      "Size after location outlier removal: 394434 records.\n",
      "--> 41 records removed!\n"
     ]
    }
   ],
   "source": [
    "df_shape_before_location_outlier_drop = df.shape\n",
    "\n",
    "Q1 = df['X_BLOCK'].quantile(0.01)\n",
    "Q3 = df['X_BLOCK'].quantile(0.99)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df.loc[(df['X_BLOCK'] >= lower_bound) & (df['X_BLOCK'] <= upper_bound)]\n",
    "\n",
    "# Calculate and display rows removed\n",
    "df_shape_after_location_outlier_drop = df.shape\n",
    "print(f'Size before location outlier removal: {df_shape_before_location_outlier_drop[0]} records.')\n",
    "print(f'Size after location outlier removal: {df_shape_after_location_outlier_drop[0]} records.')\n",
    "print(f'--> {df_shape_before_location_outlier_drop[0] - df_shape_after_location_outlier_drop[0]} records removed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in OpenStreetMap Features\n",
    "In this section, we aim to enrich our dataset with spatial features from OpenStreetMap (OSM). By querying OSM data for geographic features based on the centroids of the X and Y grid blocks (calculated from latitude and longitude), we can incorporate valuable context such as the proximity to roads, points of interest, or land use types. This spatial data enhances our analysis by providing a richer understanding of the environment in which the crimes occur, potentially improving predictive modeling. By leveraging OpenStreetMap data, we can gather additional information about the geographical characteristics of each grid cell, allowing for more nuanced predictions based on spatial context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map Size Before Margin (in blocks): Upper Left Corner: (32154, 294550), Lower Right Corner: (35553, 292331)\n",
      "Map Size After Margin (in blocks): Upper Left Corner: (31754, 294950), Lower Right Corner: (35953, 291931)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "# Import osmium to parse the OSM files\n",
    "import osmium\n",
    "\n",
    "# Re-define the UTM projections from earlier\n",
    "utm_proj = pyproj.Proj(proj=\"utm\", zone=13, datum=\"WGS84\")\n",
    "latlon_proj = pyproj.Proj(proj=\"latlong\", datum=\"WGS84\")\n",
    "\n",
    "# Define tranformers\n",
    "latlon_to_utm_transformer = pyproj.Transformer.from_proj(latlon_proj, utm_proj)\n",
    "utm_to_latlon_transformer = pyproj.Transformer.from_proj(utm_proj, latlon_proj)\n",
    "\n",
    "'''\n",
    "    Generate a Grid of Map Blocks/Cells from predefined corners.\n",
    "'''\n",
    "def gen_blocks_from_coordinates(southwest_corner, northeast_corner, database_path):\n",
    "    # Bounding corners\n",
    "    def dec_coordinates(str_coordinates):\n",
    "        parts = str_coordinates.split(\",\")\n",
    "        \n",
    "        # Extract latitude from the first part and longitude from the second part\n",
    "        lat = float(re.findall(r\"\\d+\\.\\d+\", parts[0])[0])\n",
    "        lon = float(re.findall(r\"\\d+\\.\\d+\", parts[1])[0])\n",
    "        \n",
    "        # Adjust sign based on N/S and E/W indicators\n",
    "        if \"S\" in parts[0]:\n",
    "            lat = -lat\n",
    "        if \"W\" in parts[1]:\n",
    "            lon = -lon\n",
    "            \n",
    "        return lon, lat  # Return (longitude, latitude)\n",
    "\n",
    "    southwest_lon, southwest_lat = dec_coordinates(southwest_corner)\n",
    "    northeast_lon, northeast_lat = dec_coordinates(northeast_corner)\n",
    "\n",
    "    # Define block size in meters (15 meters as mentioned)\n",
    "    block_size = 15\n",
    "\n",
    "    # Create a transformer for converting lat/lon to UTM\n",
    "    latlon_to_utm_transformer = pyproj.Transformer.from_proj(latlon_proj, utm_proj)\n",
    "\n",
    "    # Convert southwest and northeast corners to UTM\n",
    "    southwest_x, southwest_y = latlon_to_utm_transformer.transform(southwest_lon, southwest_lat)\n",
    "    northeast_x, northeast_y = latlon_to_utm_transformer.transform(northeast_lon, northeast_lat)\n",
    "\n",
    "    # Calculate the area width and height in meters\n",
    "    area_width = northeast_x - southwest_x\n",
    "    area_height = northeast_y - southwest_y\n",
    "\n",
    "    # Calculate the number of blocks in the area\n",
    "    num_x_blocks = int(area_width // block_size)\n",
    "    num_y_blocks = int(area_height // block_size)\n",
    "\n",
    "    # Create SQLite database and table\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store the map cells\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS blocks (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            x_block INTEGER,\n",
    "            y_block INTEGER,\n",
    "            cent_lat REAL,\n",
    "            cent_lon REAL\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Function to calculate the centroid of a block (in UTM)\n",
    "    def get_centroid(x_block, y_block, grid_size=15):\n",
    "        # Create a transformer for converting UTM to lat/lon\n",
    "        utm_to_latlon_transformer = pyproj.Transformer.from_proj(utm_proj, latlon_proj)\n",
    "        \n",
    "        # Get the bottom-left corner coordinates in UTM\n",
    "        x_origin, y_origin = x_block * grid_size, y_block * grid_size\n",
    "        \n",
    "        # Calculate the centroid by moving half the grid size in both directions\n",
    "        x_centroid = x_origin + grid_size / 2\n",
    "        y_centroid = y_origin + grid_size / 2\n",
    "        \n",
    "        # Convert UTM coordinates to latitude and longitude\n",
    "        lon, lat = utm_to_latlon_transformer.transform(x_centroid, y_centroid)\n",
    "        \n",
    "        return lat, lon\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    total_blocks = num_x_blocks * num_y_blocks\n",
    "\n",
    "    # Set the batch size\n",
    "    batch_size = 100000\n",
    "    batch_data = []\n",
    "\n",
    "    # Init the progress bar\n",
    "    progress_bar = tqdm(total=total_blocks, desc=\"Identifying Block Centroids\", position=0, ncols=120)\n",
    "\n",
    "    # Loop through each block and calculate the centroid\n",
    "    for y_block in range(num_y_blocks):\n",
    "        for x_block in range(num_x_blocks):\n",
    "            # Calculate the centroid for the current block\n",
    "            lat, lon = get_centroid(x_block, y_block, block_size)\n",
    "            \n",
    "            # Append data to batch\n",
    "            batch_data.append((x_block, y_block, lat, lon))\n",
    "            \n",
    "            # If batch size is reached, execute the batch insert\n",
    "            if len(batch_data) >= batch_size:\n",
    "                cursor.executemany('''\n",
    "                    INSERT INTO blocks (x_block, y_block, cent_lat, cent_lon)\n",
    "                    VALUES (?, ?, ?, ?)\n",
    "                ''', batch_data)\n",
    "                \n",
    "                # Manually update the progress bar after each block\n",
    "                progress_bar.update(len(batch_data))\n",
    "                \n",
    "                conn.commit()  # Commit after each batch\n",
    "                batch_data = []  # Clear the batch data\n",
    "\n",
    "    # Insert any remaining data after the loop\n",
    "    if batch_data:\n",
    "        cursor.executemany('''\n",
    "            INSERT INTO blocks (x_block, y_block, cent_lat, cent_lon)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        ''', batch_data)\n",
    "\n",
    "        progress_bar.update(len(batch_data))\n",
    "\n",
    "        conn.commit()  # Final commit for remaining data\n",
    "\n",
    "    # Close the progress bar once finished\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Close the SQLite connection\n",
    "    conn.close()\n",
    "\n",
    "'''\n",
    "    Generate a map based on the boundaries of the available crime location data, plus a margin\n",
    "'''\n",
    "def gen_map_from_crime_location_data_with_margin(crime_df, margin, database_path):\n",
    "    # Get the limits of the locations saved within the data frame\n",
    "    x_max = crime_df['X_BLOCK'].max()\n",
    "    x_min = crime_df['X_BLOCK'].min()\n",
    "    y_max = crime_df['Y_BLOCK'].max()\n",
    "    y_min = crime_df['Y_BLOCK'].min()\n",
    "\n",
    "    # Calculate the limits with the \n",
    "    x_max_margin = x_max + margin\n",
    "    x_min_margin = x_min - margin\n",
    "    y_max_margin = y_max + margin\n",
    "    y_min_margin = y_min - margin\n",
    "\n",
    "    # Print the map size\n",
    "    print(f\"Map Size Before Margin (in blocks): Upper Left Corner: ({x_min}, {y_max}), Lower Right Corner: ({x_max}, {y_min})\")\n",
    "    print(f\"Map Size After Margin (in blocks): Upper Left Corner: ({x_min_margin}, {y_max_margin}), Lower Right Corner: ({x_max_margin}, {y_min_margin})\")\n",
    "\n",
    "    return\n",
    "\n",
    "    # Function to get the edges of the box in lon/lat\n",
    "    def block_to_latlon(x, y):\n",
    "        # Project from UTM to latlon\n",
    "        transformer = pyproj.Transformer.from_crs(f\"epsg:32613\", \"epsg:4326\", always_xy=True)\n",
    "        return transformer.transform(x * GRID_SIZE, y * GRID_SIZE)\n",
    "\n",
    "    min_longitude, min_latitude = block_to_latlon(x_min_margin, y_min_margin)\n",
    "    max_longitude, max_latitude = block_to_latlon(x_max_margin, y_max_margin)\n",
    "    print(f\"    (lon, lat): ({min_longitude},{min_latitude}) ({max_longitude},{max_latitude})\")\n",
    "\n",
    "    # Loop through the each possible block in the map, including the margins\n",
    "    total_blocks = (x_max_margin - x_min_margin) * (y_max_margin - y_min_margin)\n",
    "    print(f'--> Total map grid cells: {total_blocks}')\n",
    "    \n",
    "    # Create SQLite database and table\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store the map cells\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS blocks (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            x INTEGER,\n",
    "            y INTEGER,\n",
    "            c_lat REAL,\n",
    "            c_lon REAL,\n",
    "            tags TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Set the batch size\n",
    "    batch_size = 1\n",
    "    batch_data = []\n",
    "    \n",
    "    # Init the progress bar\n",
    "    progress_bar = tqdm(total=total_blocks, desc=\"Building Map\", position=0, ncols=120)\n",
    "\n",
    "    for x in range(x_min_margin, x_max_margin + 1):\n",
    "        for y in range(y_min_margin, y_max_margin + 1):\n",
    "            # Get important latitudes and longitudes\n",
    "            center_lon, center_lat = block_to_latlon(x + (GRID_SIZE / 2), y - (GRID_SIZE / 2))\n",
    "\n",
    "            tags = []\n",
    "            \n",
    "            for obj in osmium.FileProcessor('../denver_filtered.osm.pbf', osmium.osm.NODE):\n",
    "                if obj.tags:\n",
    "                    tags += obj,tags\n",
    "                try:\n",
    "                    if osmium.geom.haversine_distance(osmium.osm.Location(center_lon, center_lat), obj.location) < (GRID_SIZE * 1.5):\n",
    "                        continue\n",
    "                except:\n",
    "                    print(obj)\n",
    "            \n",
    "            print(tags)\n",
    "            \n",
    "            batch_data.append((\n",
    "                x,          #\n",
    "                y,          #\n",
    "                center_lon, #\n",
    "                center_lat, #\n",
    "                str(tags)        #\n",
    "            ))\n",
    "\n",
    "            # If batch size is reached, execute the batch insert\n",
    "            if len(batch_data) >= batch_size:\n",
    "                cursor.executemany('''\n",
    "                    INSERT INTO blocks (x, y, c_lat, c_lon, tags)\n",
    "                    VALUES (?, ?, ?, ?, ?)\n",
    "                ''', batch_data)\n",
    "                \n",
    "                # Manually update the progress bar after each block\n",
    "                progress_bar.update(len(batch_data))\n",
    "                \n",
    "                conn.commit()  # Commit after each batch\n",
    "                batch_data = []  # Clear the batch data\n",
    "            \n",
    "    # Insert any remaining data after the loop\n",
    "    if batch_data:\n",
    "        cursor.executemany('''\n",
    "            INSERT INTO blocks (x, y, c_lat, c_lon, tags)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        ''', batch_data)\n",
    "\n",
    "        progress_bar.update(len(batch_data))\n",
    "\n",
    "        conn.commit()  # Final commit for remaining data\n",
    "\n",
    "    # Close the SQLite connection\n",
    "    conn.close()    \n",
    "    \n",
    "    # Close the progress bar once finished\n",
    "    progress_bar.close()\n",
    "\n",
    "# Old method was just a fixed area\n",
    "southwest_corner = \"39.53440° N, 105.24364° W\"\n",
    "northeast_corner = \"40.03841° N, 104.58877° W\"\n",
    "database_path = 'map_grid.db'\n",
    "#gen_blocks_from_coordinates(southwest_corner, northeast_corner, database_path)\n",
    "\n",
    "gen_map_from_crime_location_data_with_margin(df, 400, 'map.db')\n",
    "# -- Skipping... see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "12676781 * 17 / 60 / 60 / 24 / 365 = 6.8336275051 \\text{ years to process the OSM data}\n",
    "$$\n",
    "For now, I will set aside the extraction of OpenStreetMap (OSM) features due to the excessive processing time — approximately 6.83 years — required to handle the data with my current approach. The complexity of querying and filtering OSM data, even with optimization attempts, has proven to be a significant bottleneck. As a result, I will proceed with exploratory data analysis (EDA) using the existing crime dataset without incorporating OSM features. This will allow me to focus on other aspects of the analysis and revisit the OSM integration if a more efficient method becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the initial dataframe\n",
    "original_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime Type Model (Gradient Boosting Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    47402\n",
      "148    32539\n",
      "35     22177\n",
      "154    20602\n",
      "153    18918\n",
      "       ...  \n",
      "92         2\n",
      "177        2\n",
      "68         2\n",
      "90         2\n",
      "86         2\n",
      "Name: count, Length: 171, dtype: int64\n",
      "Test Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    11851\n",
      "148     8135\n",
      "35      5544\n",
      "154     5151\n",
      "153     4730\n",
      "       ...  \n",
      "113        1\n",
      "86         1\n",
      "123        1\n",
      "109        1\n",
      "94         1\n",
      "Name: count, Length: 164, dtype: int64\n",
      "Accuracy: 0.1315062241715894\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.03      0.05      0.04        61\n",
      "           2       0.00      0.00      0.00       187\n",
      "           3       0.10      0.00      0.01      1442\n",
      "           4       0.07      0.00      0.00       656\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00        26\n",
      "           9       0.00      0.00      0.00        64\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00        30\n",
      "          12       0.00      0.00      0.00        47\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.04      0.00      0.01       981\n",
      "          15       0.04      0.02      0.03       149\n",
      "          16       0.19      0.02      0.03      2916\n",
      "          18       0.01      0.03      0.01        39\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00        23\n",
      "          21       0.00      0.00      0.00        65\n",
      "          22       0.01      0.02      0.01       127\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.13      0.05      0.08      1845\n",
      "          25       0.03      0.00      0.00       505\n",
      "          26       0.01      0.01      0.01        88\n",
      "          27       0.00      0.00      0.00        76\n",
      "          28       0.03      0.02      0.02      1240\n",
      "          29       0.10      0.00      0.00      1699\n",
      "          30       0.00      0.00      0.00        25\n",
      "          31       0.00      0.00      0.00        28\n",
      "          32       0.14      0.13      0.13        79\n",
      "          33       0.00      0.00      0.00         9\n",
      "          34       0.03      0.06      0.04       497\n",
      "          35       0.09      0.01      0.02      5544\n",
      "          36       0.05      0.01      0.02      3310\n",
      "          37       0.08      0.13      0.10      2918\n",
      "          38       0.04      0.09      0.06        86\n",
      "          39       0.00      0.00      0.00         9\n",
      "          40       0.01      0.00      0.00       726\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.01      0.01      0.01       166\n",
      "          45       0.03      0.07      0.05       202\n",
      "          46       0.00      0.00      0.00         4\n",
      "          47       0.00      0.00      0.00        18\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         9\n",
      "          50       0.00      0.00      0.00        10\n",
      "          51       0.02      0.03      0.02       140\n",
      "          52       0.05      0.04      0.04        54\n",
      "          53       0.01      0.02      0.01        43\n",
      "          54       0.00      0.00      0.00        11\n",
      "          55       0.00      0.00      0.00        37\n",
      "          56       0.00      0.00      0.00        28\n",
      "          57       0.04      0.07      0.05       521\n",
      "          58       0.00      0.01      0.01       194\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.02      0.03      0.03        67\n",
      "          61       0.08      0.07      0.08       195\n",
      "          62       0.10      0.03      0.05       833\n",
      "          63       0.32      0.19      0.24      1081\n",
      "          64       0.00      0.00      0.00        23\n",
      "          65       0.00      0.00      0.00        33\n",
      "          67       0.00      0.00      0.00        11\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00        70\n",
      "          72       0.00      0.00      0.00       118\n",
      "          73       0.01      0.07      0.02        15\n",
      "          74       0.01      0.01      0.01       152\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        41\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00        17\n",
      "          79       0.00      0.00      0.00        16\n",
      "          80       0.01      0.01      0.01       328\n",
      "          81       0.03      0.01      0.01       281\n",
      "          82       0.00      0.00      0.00       112\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00        26\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.01      0.00      0.00       289\n",
      "          88       0.00      0.00      0.00       135\n",
      "          89       0.00      0.00      0.00        81\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00        76\n",
      "          94       0.00      0.00      0.00         1\n",
      "          96       0.02      0.03      0.03        39\n",
      "          97       0.00      0.00      0.00         9\n",
      "          98       0.00      0.00      0.00       142\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        47\n",
      "         101       0.00      0.00      0.00        54\n",
      "         102       0.01      1.00      0.02         1\n",
      "         103       0.32      0.27      0.30       313\n",
      "         104       0.05      0.07      0.06        46\n",
      "         105       0.00      0.00      0.00         9\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.00      0.00      0.00      1047\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         4\n",
      "         111       0.00      0.00      0.00        52\n",
      "         112       0.00      0.00      0.00         9\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         5\n",
      "         115       0.03      0.03      0.03        58\n",
      "         116       0.01      0.00      0.01       281\n",
      "         117       0.04      0.02      0.02       237\n",
      "         118       0.00      0.00      0.00        10\n",
      "         119       0.00      0.00      0.00        26\n",
      "         120       0.00      0.00      0.00       152\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00        27\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.10      0.32      0.15       107\n",
      "         125       0.00      0.00      0.00         2\n",
      "         126       0.00      0.00      0.00        86\n",
      "         127       0.15      0.04      0.06       591\n",
      "         128       0.00      0.00      0.00        64\n",
      "         129       0.00      0.00      0.00        23\n",
      "         131       0.03      0.05      0.03        42\n",
      "         132       0.04      0.01      0.01       411\n",
      "         133       0.00      0.00      0.00       197\n",
      "         134       0.00      0.00      0.00        44\n",
      "         135       0.01      0.01      0.01        76\n",
      "         136       0.01      0.00      0.00       641\n",
      "         137       0.68      0.76      0.72       263\n",
      "         138       0.09      0.12      0.10        33\n",
      "         139       0.00      0.00      0.00        40\n",
      "         140       0.12      0.01      0.02      1889\n",
      "         141       0.00      0.00      0.00         9\n",
      "         142       0.00      0.00      0.00        20\n",
      "         143       0.22      0.32      0.26       150\n",
      "         144       0.09      0.00      0.01      1700\n",
      "         145       0.00      0.00      0.00       149\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.19      0.08      0.11      8135\n",
      "         150       0.18      0.58      0.28     11851\n",
      "         151       0.00      0.00      0.00        13\n",
      "         152       0.38      0.23      0.28       305\n",
      "         153       0.07      0.01      0.02      4730\n",
      "         154       0.24      0.04      0.06      5151\n",
      "         155       0.00      0.00      0.00        34\n",
      "         156       0.00      0.00      0.00        55\n",
      "         157       0.43      0.28      0.34      2714\n",
      "         158       0.00      0.00      0.00        14\n",
      "         159       0.08      0.03      0.04       213\n",
      "         160       0.00      0.00      0.00       156\n",
      "         161       0.05      0.00      0.00      1081\n",
      "         162       0.00      0.00      0.00       605\n",
      "         163       0.00      0.00      0.00        15\n",
      "         164       0.01      0.02      0.01       691\n",
      "         165       0.00      0.00      0.00         7\n",
      "         166       0.02      0.00      0.01       324\n",
      "         167       0.00      0.00      0.00        85\n",
      "         168       0.01      0.01      0.01        71\n",
      "         169       0.01      0.01      0.01       257\n",
      "         170       0.00      0.00      0.00        77\n",
      "         171       0.00      0.00      0.00        95\n",
      "         172       0.04      0.01      0.02       135\n",
      "         173       0.00      0.00      0.00       144\n",
      "         174       0.23      0.15      0.18      1707\n",
      "         175       0.00      0.00      0.00         2\n",
      "         176       0.00      0.00      0.00        17\n",
      "         177       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.13     78886\n",
      "   macro avg       0.03      0.03      0.03     78886\n",
      "weighted avg       0.13      0.13      0.10     78886\n",
      "\n",
      "Precision (weighted): 0.1342643190505953\n",
      "Recall (weighted): 0.1315062241715894\n",
      "F1 Score (weighted): 0.0959251651590038\n",
      "Root Mean Squared Error (RMSE): 74.53985958898483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "df['OFFENSE_TYPE_ID'] = encoder.fit_transform(df['OFFENSE_TYPE_ID'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Remove rare classes with only 1 instance\n",
    "class_counts = y.value_counts()\n",
    "rare_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "# Filter out the rare classes from the dataset\n",
    "filtered_df = df[~df['OFFENSE_TYPE_ID'].isin(rare_classes)]\n",
    "\n",
    "# Update X and y after removing rare classes\n",
    "X = filtered_df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = filtered_df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Ensure no class is left with fewer than 2 members in either train or test\n",
    "train_class_counts = y_train.value_counts()\n",
    "test_class_counts = y_test.value_counts()\n",
    "\n",
    "# Print out the counts for train and test to debug\n",
    "print(\"Train Class Distribution:\\n\", train_class_counts)\n",
    "print(\"Test Class Distribution:\\n\", test_class_counts)\n",
    "\n",
    "# Check if any class is left with 1 sample in the train set\n",
    "if any(train_class_counts < 2):\n",
    "    print(\"Some classes in the train set have less than 2 samples. Consider further reducing or combining classes.\")\n",
    "else:\n",
    "    # Initialize and train the model\n",
    "    model = HistGradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Classification report (includes precision, recall, F1-score)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Precision, Recall, and F1 Score\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"Precision (weighted): {precision}\")\n",
    "    print(f\"Recall (weighted): {recall}\")\n",
    "    print(f\"F1 Score (weighted): {f1}\")\n",
    "\n",
    "    # RMSE (Root Mean Squared Error)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "    # To decode the predictions back to the original labels\n",
    "    decoded_predictions = encoder.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime Likelihood Model (Gradient Boosting Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.12031554289457475\n",
      "Root Mean Squared Error (RMSE): 0.34686530944240407\n",
      "Mean Absolute Error (MAE): 0.1601346201692215\n",
      "R2 Score: 0.05012391604887978\n"
     ]
    }
   ],
   "source": [
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Group by grid cell, day of year, and hour to count crimes\n",
    "crime_counts = df.groupby(['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']).size().reset_index(name='CRIME_COUNT')\n",
    "\n",
    "# Features and target\n",
    "X = crime_counts[['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']]\n",
    "y = crime_counts['CRIME_COUNT']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = HistGradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Conclusions & Evaluations of These Models\n",
    "The regression model doesn't perform very well, with a low R² score of 0.052, meaning it doesn’t explain much of the variation in crime counts. The Mean Squared Error and Root Mean Squared Error suggest there's still a lot of room for improvement, with predictions off by about 0.35 crimes on average. The classification model also struggles, with low precision, recall, and F1 scores, pointing to issues with class imbalance and poor overall prediction accuracy. Although the accuracy is a bit higher, it doesn't capture the full picture of how well the model is performing across all classes. Both models need better feature engineering and more work on handling imbalances to improve their results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Alternatives: Neural Networks\n",
    "Given the poor performance of my initial models, I am now exploring neural networks, including deep neural networks. With a limited number of features available and the infeasibility of incorporating OSM data, I believe that more complex models like these could help improve predictions. Neural networks are well-suited to handle intricate patterns in data and may offer better performance compared to the models I've tried so far. This approach seems like a promising next step to tackle the issues with accuracy and model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.0980\n",
      "Epoch [11/100], Loss: 0.2976\n",
      "Epoch [21/100], Loss: 0.1432\n",
      "Epoch [31/100], Loss: 0.1298\n",
      "Epoch [41/100], Loss: 0.1266\n",
      "Epoch [51/100], Loss: 0.1257\n",
      "Epoch [61/100], Loss: 0.1254\n",
      "Epoch [71/100], Loss: 0.1252\n",
      "Epoch [81/100], Loss: 0.1251\n",
      "Epoch [91/100], Loss: 0.1250\n",
      "Mean Squared Error (MSE): 0.1269\n",
      "Root Mean Squared Error (RMSE): 0.3562\n",
      "Mean Absolute Error (MAE): 0.1714\n",
      "R2 Score: -0.0015\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Group by grid cell, day of year, and hour to count crimes\n",
    "crime_counts = df.groupby(['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']).size().reset_index(name='CRIME_COUNT')\n",
    "\n",
    "# Features and target\n",
    "X = crime_counts[['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']]\n",
    "y = crime_counts['CRIME_COUNT'].values\n",
    "\n",
    "# Split data into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "class CrimeLikelihoodNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrimeLikelihoodNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.fc5 = nn.Linear(32, 16)\n",
    "        self.bn5 = nn.BatchNorm1d(16)\n",
    "        self.fc6 = nn.Linear(16, 1) \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = torch.relu(self.bn5(self.fc5(x)))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = CrimeLikelihoodNeuralNetwork(input_dim)\n",
    "\n",
    "# Check if MPS (MacBook Metal GPU support) is available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "\n",
    "# Moving the model and data to the new device if it is enabled\n",
    "model.to(device)\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "number_epochs = 100\n",
    "for epoch in range(number_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{number_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluating the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "    \n",
    "    # Move the tensor to CPU before converting to NumPy array\n",
    "    y_pred = y_pred_tensor.cpu().numpy()\n",
    "\n",
    "    # Calculate RMSE, MAE, and R2\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print key metrics\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Neural Networks\n",
    "This section is not important, I simply copied a few different neural networks that I attempted to use. These are difficult to tune and I don't think that my data is helping either. I tried others beyond what I have pasted in this section for posterity.\n",
    "\n",
    "```python\n",
    "class CrimeLikelihoodNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrimeLikelihoodNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 16)\n",
    "        self.fc6 = nn.Linear(16, 1) \n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "* Mean Squared Error (MSE): 0.5807\n",
    "* Root Mean Squared Error (RMSE): 0.7621\n",
    "* Mean Absolute Error (MAE): 0.6745\n",
    "* R2 Score: -3.6087\n",
    "```python\n",
    "class CrimeLikelihoodNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrimeLikelihoodNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 64)\n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.fc8 = nn.Linear(32, 16)\n",
    "        self.fc9 = nn.Linear(16, 8)\n",
    "        self.fc10 = nn.Linear(8, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc8(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc9(x))\n",
    "        x = self.fc10(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "```python\n",
    "class CrimeLikelihoodNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CrimeLikelihoodNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        self.fc5 = nn.Linear(32, 16)\n",
    "        self.bn5 = nn.BatchNorm1d(16)\n",
    "        self.fc6 = nn.Linear(16, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.bn3(self.fc3(x)))\n",
    "        x = torch.relu(self.bn4(self.fc4(x)))\n",
    "        x = torch.relu(self.bn5(self.fc5(x)))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions Regarding Neural Networks\n",
    "The neural network showed decent results with 350,000 data points but struggled with high variance and overfitting. While the model improved over time, its performance didn't meet expectations in terms of generalization. The complexity of the data may have been better suited for a different model. Given the task and dataset size, simpler models like random forests could be more effective. Moving forward, testing a random forest might provide better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Alternatives: Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime Likelihood Model (RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.13450888916507858\n",
      "Root Mean Squared Error (RMSE): 0.3667545353026716\n",
      "Mean Absolute Error (MAE): 0.17365937525892786\n",
      "R2 Score: -0.061930768235775036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Group by grid cell, day of year, and hour to count crimes\n",
    "crime_counts = df.groupby(['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']).size().reset_index(name='CRIME_COUNT')\n",
    "\n",
    "# Features and target\n",
    "X = crime_counts[['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']]\n",
    "y = crime_counts['CRIME_COUNT']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crime Type Model (RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    47402\n",
      "148    32539\n",
      "35     22177\n",
      "154    20602\n",
      "153    18918\n",
      "       ...  \n",
      "92         2\n",
      "177        2\n",
      "68         2\n",
      "90         2\n",
      "86         2\n",
      "Name: count, Length: 171, dtype: int64\n",
      "Test Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    11851\n",
      "148     8135\n",
      "35      5544\n",
      "154     5151\n",
      "153     4730\n",
      "       ...  \n",
      "113        1\n",
      "86         1\n",
      "123        1\n",
      "109        1\n",
      "94         1\n",
      "Name: count, Length: 164, dtype: int64\n",
      "Accuracy: 0.1844433739827092\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.05      0.03      0.04        61\n",
      "           2       0.02      0.01      0.01       187\n",
      "           3       0.06      0.04      0.04      1442\n",
      "           4       0.01      0.00      0.00       656\n",
      "           6       0.07      0.04      0.05        28\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00        26\n",
      "           9       0.00      0.00      0.00        64\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.08      0.03      0.05        30\n",
      "          12       0.00      0.00      0.00        47\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.02      0.01      0.01       981\n",
      "          15       0.03      0.02      0.02       149\n",
      "          16       0.11      0.09      0.10      2916\n",
      "          18       0.00      0.00      0.00        39\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00        23\n",
      "          21       0.00      0.00      0.00        65\n",
      "          22       0.00      0.00      0.00       127\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.25      0.21      0.23      1845\n",
      "          25       0.03      0.01      0.02       505\n",
      "          26       0.10      0.06      0.07        88\n",
      "          27       0.00      0.00      0.00        76\n",
      "          28       0.06      0.03      0.04      1240\n",
      "          29       0.05      0.03      0.04      1699\n",
      "          30       0.09      0.04      0.06        25\n",
      "          31       0.11      0.04      0.05        28\n",
      "          32       0.18      0.14      0.16        79\n",
      "          33       0.17      0.11      0.13         9\n",
      "          34       0.20      0.08      0.12       497\n",
      "          35       0.11      0.10      0.10      5544\n",
      "          36       0.08      0.06      0.07      3310\n",
      "          37       0.19      0.21      0.20      2918\n",
      "          38       0.29      0.26      0.27        86\n",
      "          39       0.00      0.00      0.00         9\n",
      "          40       0.01      0.01      0.01       726\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.02      0.01      0.01       166\n",
      "          45       0.24      0.24      0.24       202\n",
      "          46       0.00      0.00      0.00         4\n",
      "          47       0.00      0.00      0.00        18\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         9\n",
      "          50       0.25      0.10      0.14        10\n",
      "          51       0.04      0.03      0.03       140\n",
      "          52       0.03      0.02      0.02        54\n",
      "          53       0.04      0.02      0.03        43\n",
      "          54       0.14      0.09      0.11        11\n",
      "          55       0.08      0.03      0.04        37\n",
      "          56       0.00      0.00      0.00        28\n",
      "          57       0.06      0.05      0.05       521\n",
      "          58       0.04      0.03      0.03       194\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.02      0.01      0.02        67\n",
      "          61       0.06      0.04      0.04       195\n",
      "          62       0.06      0.04      0.05       833\n",
      "          63       0.28      0.31      0.30      1081\n",
      "          64       0.00      0.00      0.00        23\n",
      "          65       0.00      0.00      0.00        33\n",
      "          67       0.00      0.00      0.00        11\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00        70\n",
      "          72       0.00      0.00      0.00       118\n",
      "          73       0.22      0.13      0.17        15\n",
      "          74       0.02      0.01      0.01       152\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        41\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00        17\n",
      "          79       0.00      0.00      0.00        16\n",
      "          80       0.03      0.01      0.01       328\n",
      "          81       0.05      0.01      0.02       281\n",
      "          82       0.02      0.01      0.01       112\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00        26\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.01      0.00      0.01       289\n",
      "          88       0.00      0.00      0.00       135\n",
      "          89       0.00      0.00      0.00        81\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         6\n",
      "          93       0.00      0.00      0.00        76\n",
      "          94       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00        39\n",
      "          97       0.00      0.00      0.00         9\n",
      "          98       0.02      0.01      0.01       142\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        47\n",
      "         101       0.00      0.00      0.00        54\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.43      0.50      0.46       313\n",
      "         104       0.35      0.13      0.19        46\n",
      "         105       0.00      0.00      0.00         9\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.01      0.00      0.01      1047\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         4\n",
      "         111       0.00      0.00      0.00        52\n",
      "         112       0.50      0.11      0.18         9\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         5\n",
      "         115       0.10      0.12      0.11        58\n",
      "         116       0.01      0.00      0.00       281\n",
      "         117       0.01      0.00      0.00       237\n",
      "         118       0.00      0.00      0.00        10\n",
      "         119       0.00      0.00      0.00        26\n",
      "         120       0.00      0.00      0.00       152\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00        27\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.54      0.57      0.55       107\n",
      "         125       0.00      0.00      0.00         2\n",
      "         126       0.04      0.03      0.04        86\n",
      "         127       0.19      0.15      0.16       591\n",
      "         128       0.00      0.00      0.00        64\n",
      "         129       0.00      0.00      0.00        23\n",
      "         131       0.43      0.07      0.12        42\n",
      "         132       0.08      0.03      0.05       411\n",
      "         133       0.02      0.01      0.01       197\n",
      "         134       0.00      0.00      0.00        44\n",
      "         135       0.00      0.00      0.00        76\n",
      "         136       0.02      0.01      0.01       641\n",
      "         137       0.87      0.92      0.89       263\n",
      "         138       0.27      0.21      0.24        33\n",
      "         139       0.00      0.00      0.00        40\n",
      "         140       0.14      0.10      0.12      1889\n",
      "         141       0.00      0.00      0.00         9\n",
      "         142       0.00      0.00      0.00        20\n",
      "         143       0.48      0.43      0.45       150\n",
      "         144       0.11      0.05      0.07      1700\n",
      "         145       0.02      0.01      0.01       149\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.18      0.25      0.21      8135\n",
      "         150       0.24      0.46      0.32     11851\n",
      "         151       0.00      0.00      0.00        13\n",
      "         152       0.38      0.30      0.34       305\n",
      "         153       0.13      0.12      0.13      4730\n",
      "         154       0.16      0.15      0.15      5151\n",
      "         155       0.00      0.00      0.00        34\n",
      "         156       0.00      0.00      0.00        55\n",
      "         157       0.45      0.52      0.48      2714\n",
      "         158       0.00      0.00      0.00        14\n",
      "         159       0.02      0.00      0.01       213\n",
      "         160       0.00      0.00      0.00       156\n",
      "         161       0.03      0.02      0.02      1081\n",
      "         162       0.02      0.01      0.02       605\n",
      "         163       0.00      0.00      0.00        15\n",
      "         164       0.02      0.01      0.01       691\n",
      "         165       0.00      0.00      0.00         7\n",
      "         166       0.02      0.01      0.01       324\n",
      "         167       0.00      0.00      0.00        85\n",
      "         168       0.00      0.00      0.00        71\n",
      "         169       0.04      0.02      0.02       257\n",
      "         170       0.00      0.00      0.00        77\n",
      "         171       0.00      0.00      0.00        95\n",
      "         172       0.00      0.00      0.00       135\n",
      "         173       0.00      0.00      0.00       144\n",
      "         174       0.30      0.33      0.31      1707\n",
      "         175       0.00      0.00      0.00         2\n",
      "         176       0.00      0.00      0.00        17\n",
      "         177       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.18     78886\n",
      "   macro avg       0.06      0.05      0.05     78886\n",
      "weighted avg       0.15      0.18      0.16     78886\n",
      "\n",
      "Precision (weighted): 0.15293471081467375\n",
      "Recall (weighted): 0.1844433739827092\n",
      "F1 Score (weighted): 0.1616221309064477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "df['OFFENSE_TYPE_ID'] = encoder.fit_transform(df['OFFENSE_TYPE_ID'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Remove rare classes with only 1 instance\n",
    "class_counts = y.value_counts()\n",
    "rare_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "# Filter out the rare classes from the dataset\n",
    "filtered_df = df[~df['OFFENSE_TYPE_ID'].isin(rare_classes)]\n",
    "\n",
    "# Update X and y after removing rare classes\n",
    "X = filtered_df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = filtered_df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Ensure no class is left with fewer than 2 members in either train or test\n",
    "train_class_counts = y_train.value_counts()\n",
    "test_class_counts = y_test.value_counts()\n",
    "\n",
    "# Print out the counts for train and test to debug\n",
    "print(\"Train Class Distribution:\\n\", train_class_counts)\n",
    "print(\"Test Class Distribution:\\n\", test_class_counts)\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report (includes precision, recall, F1-score)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Precision, Recall, and F1 Score\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "print(f\"Precision (weighted): {precision}\")\n",
    "print(f\"Recall (weighted): {recall}\")\n",
    "print(f\"F1 Score (weighted): {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Conclusions\n",
    "The Random Forest model did not show significant improvement compared to the Gradient Boosting or Neural Network models. Despite being a powerful ensemble method, its performance was limited, as evidenced by the relatively low precision, recall, and F1 score. These results indicate that while Random Forest can be effective in some cases, it did not provide the expected boost in predictive power over the other models tested. Further tuning or a different approach may be necessary to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Gradient Boosting Models\n",
    "Since we entertained some of the best performance on the Gradient Boosted models, I am moving forward with using them as my final models to make predictions in the production environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References to be assigned in the future once we have identified the models that we want to pickle\n",
    "classifier_model = None\n",
    "regressor_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning the Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    47402\n",
      "148    32539\n",
      "35     22177\n",
      "154    20602\n",
      "153    18918\n",
      "       ...  \n",
      "46        18\n",
      "69        17\n",
      "110       16\n",
      "10        15\n",
      "70        15\n",
      "Name: count, Length: 149, dtype: int64\n",
      "Test Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    11851\n",
      "148     8135\n",
      "35      5544\n",
      "154     5151\n",
      "153     4730\n",
      "       ...  \n",
      "69         4\n",
      "110        4\n",
      "10         4\n",
      "70         4\n",
      "46         4\n",
      "Name: count, Length: 149, dtype: int64\n",
      "\n",
      "Best Parameters: {'min_samples_leaf': 30, 'max_iter': 500, 'max_depth': None, 'learning_rate': 0.01, 'l2_regularization': 0.01}\n",
      "Accuracy: 0.22740125530970645\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.23      0.05      0.08        61\n",
      "           2       0.00      0.00      0.00       187\n",
      "           3       0.11      0.01      0.01      1442\n",
      "           4       0.00      0.00      0.00       656\n",
      "           6       0.00      0.00      0.00        28\n",
      "           8       0.00      0.00      0.00        26\n",
      "           9       0.00      0.00      0.00        64\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.20      0.03      0.06        30\n",
      "          12       0.00      0.00      0.00        47\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.00      0.00      0.00       981\n",
      "          15       0.12      0.01      0.01       149\n",
      "          16       0.21      0.12      0.15      2916\n",
      "          18       0.00      0.00      0.00        39\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00        23\n",
      "          21       0.00      0.00      0.00        65\n",
      "          22       0.00      0.00      0.00       127\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.29      0.21      0.24      1845\n",
      "          25       0.11      0.00      0.00       505\n",
      "          26       0.11      0.03      0.05        88\n",
      "          27       0.00      0.00      0.00        76\n",
      "          28       0.14      0.00      0.00      1240\n",
      "          29       0.17      0.00      0.01      1699\n",
      "          30       0.00      0.00      0.00        25\n",
      "          31       0.33      0.04      0.06        28\n",
      "          32       0.20      0.18      0.19        79\n",
      "          33       0.00      0.00      0.00         9\n",
      "          34       0.39      0.06      0.10       497\n",
      "          35       0.20      0.01      0.02      5544\n",
      "          36       0.14      0.02      0.03      3310\n",
      "          37       0.23      0.30      0.26      2918\n",
      "          38       0.24      0.29      0.26        86\n",
      "          39       0.00      0.00      0.00         9\n",
      "          40       0.08      0.00      0.00       726\n",
      "          44       0.18      0.05      0.08       166\n",
      "          45       0.32      0.30      0.31       202\n",
      "          46       0.00      0.00      0.00         4\n",
      "          47       0.00      0.00      0.00        18\n",
      "          49       0.00      0.00      0.00         9\n",
      "          50       0.33      0.20      0.25        10\n",
      "          51       0.00      0.00      0.00       140\n",
      "          52       0.04      0.02      0.03        54\n",
      "          53       0.00      0.00      0.00        43\n",
      "          54       0.00      0.00      0.00        11\n",
      "          55       0.00      0.00      0.00        37\n",
      "          56       0.00      0.00      0.00        28\n",
      "          57       0.17      0.07      0.09       521\n",
      "          58       0.13      0.02      0.04       194\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.04      0.01      0.02        67\n",
      "          61       0.02      0.01      0.01       195\n",
      "          62       0.17      0.05      0.07       833\n",
      "          63       0.35      0.44      0.39      1081\n",
      "          64       0.00      0.00      0.00        23\n",
      "          65       0.00      0.00      0.00        33\n",
      "          67       0.00      0.00      0.00        11\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00        70\n",
      "          72       0.00      0.00      0.00       118\n",
      "          73       0.38      0.33      0.36        15\n",
      "          74       0.21      0.02      0.04       152\n",
      "          75       0.00      0.00      0.00        10\n",
      "          76       0.09      0.02      0.04        41\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00        17\n",
      "          79       0.00      0.00      0.00        16\n",
      "          80       0.00      0.00      0.00       328\n",
      "          81       0.00      0.00      0.00       281\n",
      "          82       0.00      0.00      0.00       112\n",
      "          84       0.00      0.00      0.00        26\n",
      "          87       0.00      0.00      0.00       289\n",
      "          88       0.00      0.00      0.00       135\n",
      "          89       0.00      0.00      0.00        81\n",
      "          91       0.00      0.00      0.00         6\n",
      "          93       0.00      0.00      0.00        76\n",
      "          96       0.00      0.00      0.00        39\n",
      "          97       0.00      0.00      0.00         8\n",
      "          98       0.00      0.00      0.00       142\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        47\n",
      "         101       0.00      0.00      0.00        54\n",
      "         103       0.45      0.59      0.51       313\n",
      "         104       0.25      0.15      0.19        46\n",
      "         105       0.00      0.00      0.00         9\n",
      "         107       0.00      0.00      0.00      1047\n",
      "         110       1.00      0.25      0.40         4\n",
      "         111       0.00      0.00      0.00        52\n",
      "         112       0.17      0.11      0.13         9\n",
      "         114       0.00      0.00      0.00         5\n",
      "         115       0.13      0.14      0.14        58\n",
      "         116       0.00      0.00      0.00       281\n",
      "         117       0.00      0.00      0.00       237\n",
      "         118       0.00      0.00      0.00        10\n",
      "         119       0.00      0.00      0.00        26\n",
      "         120       0.00      0.00      0.00       152\n",
      "         122       0.00      0.00      0.00        27\n",
      "         124       0.61      0.76      0.68       107\n",
      "         126       0.09      0.03      0.05        86\n",
      "         127       0.36      0.16      0.22       591\n",
      "         128       0.10      0.03      0.05        64\n",
      "         129       0.00      0.00      0.00        23\n",
      "         131       0.32      0.14      0.20        42\n",
      "         132       0.07      0.00      0.00       411\n",
      "         133       0.00      0.00      0.00       197\n",
      "         134       0.00      0.00      0.00        44\n",
      "         135       0.00      0.00      0.00        76\n",
      "         136       0.12      0.01      0.02       641\n",
      "         137       0.85      0.96      0.90       263\n",
      "         138       0.44      0.12      0.19        33\n",
      "         139       0.00      0.00      0.00        40\n",
      "         140       0.17      0.09      0.12      1889\n",
      "         141       0.00      0.00      0.00         9\n",
      "         142       0.00      0.00      0.00        20\n",
      "         143       0.39      0.49      0.43       150\n",
      "         144       0.39      0.01      0.02      1700\n",
      "         145       0.00      0.00      0.00       149\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.19      0.31      0.24      8135\n",
      "         150       0.21      0.73      0.32     11851\n",
      "         151       0.00      0.00      0.00        13\n",
      "         152       0.47      0.38      0.42       305\n",
      "         153       0.16      0.07      0.10      4730\n",
      "         154       0.22      0.10      0.14      5151\n",
      "         155       0.50      0.15      0.23        34\n",
      "         156       0.00      0.00      0.00        55\n",
      "         157       0.46      0.66      0.54      2714\n",
      "         158       0.00      0.00      0.00        14\n",
      "         159       0.00      0.00      0.00       213\n",
      "         160       0.00      0.00      0.00       156\n",
      "         161       0.00      0.00      0.00      1081\n",
      "         162       0.40      0.00      0.01       605\n",
      "         163       0.00      0.00      0.00        15\n",
      "         164       0.00      0.00      0.00       691\n",
      "         165       0.00      0.00      0.00         7\n",
      "         166       0.00      0.00      0.00       324\n",
      "         167       0.00      0.00      0.00        85\n",
      "         168       0.00      0.00      0.00        71\n",
      "         169       0.00      0.00      0.00       257\n",
      "         170       0.00      0.00      0.00        77\n",
      "         171       0.00      0.00      0.00        95\n",
      "         172       0.04      0.01      0.01       135\n",
      "         173       0.00      0.00      0.00       144\n",
      "         174       0.28      0.40      0.33      1707\n",
      "         176       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.23     78865\n",
      "   macro avg       0.10      0.07      0.07     78865\n",
      "weighted avg       0.19      0.23      0.16     78865\n",
      "\n",
      "Precision (weighted): 0.19163135273035\n",
      "Recall (weighted): 0.22740125530970645\n",
      "F1 Score (weighted): 0.16102398498675685\n",
      "Root Mean Squared Error (RMSE): 71.35365588711969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "df['OFFENSE_TYPE_ID'] = encoder.fit_transform(df['OFFENSE_TYPE_ID'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Remove rare classes with only less tha 16 instances\n",
    "class_counts = y.value_counts()\n",
    "rare_classes = class_counts[class_counts < 16].index\n",
    "\n",
    "# Filter out the rare classes from the dataset\n",
    "filtered_df = df[~df['OFFENSE_TYPE_ID'].isin(rare_classes)]\n",
    "\n",
    "# Update X and y after removing rare classes\n",
    "X = filtered_df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = filtered_df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Ensure no class is left with fewer than 2 members in either train or test\n",
    "train_class_counts = y_train.value_counts()\n",
    "test_class_counts = y_test.value_counts()\n",
    "\n",
    "# Print out the counts for train and test to debug\n",
    "print(\"Train Class Distribution:\\n\", train_class_counts)\n",
    "print(\"Test Class Distribution:\\n\", test_class_counts)\n",
    "\n",
    "# Randomized search parameters\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_iter': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 3, 5, 7],\n",
    "    'l2_regularization': [0, 0.01, 0.1, 1.0],\n",
    "    'min_samples_leaf': [10, 20, 30, 50],\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = HistGradientBoostingClassifier()\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring='f1_weighted',  # Optimize for weighted F1-score\n",
    "    random_state=42,\n",
    "    n_jobs=-1   # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\nBest Parameters:\", random_search.best_params_)\n",
    "\n",
    "# Train the final model with best parameters\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report (includes precision, recall, F1-score)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Precision, Recall, and F1 Score1\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "print(f\"Precision (weighted): {precision}\")\n",
    "print(f\"Recall (weighted): {recall}\")\n",
    "print(f\"F1 Score (weighted): {f1}\")\n",
    "\n",
    "# RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# To decode the predictions back to the original labels\n",
    "decoded_predictions = encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Save the best classifier model\n",
    "classifier_model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning the Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Best Parameters: {'l2_regularization': 0.1, 'learning_rate': 0.2, 'max_depth': 7, 'max_iter': 100, 'min_samples_leaf': 10}\n",
      "\n",
      "Evaluation Metrics:\n",
      "Mean Squared Error (MSE): 0.12060748392795712\n",
      "Root Mean Squared Error (RMSE): 0.3472858821316483\n",
      "Mean Absolute Error (MAE): 0.15950891086751307\n",
      "R2 Score: 0.047819078295898376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Group by grid cell, day of year, and hour to count crimes\n",
    "crime_counts = df.groupby(['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']).size().reset_index(name='CRIME_COUNT')\n",
    "\n",
    "# Features and target\n",
    "X = crime_counts[['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR_SIN', 'HOUR_COS']]\n",
    "y = crime_counts['CRIME_COUNT']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_depth': [7],\n",
    "    'l2_regularization': [0, 0.01, 0.1],\n",
    "    'min_samples_leaf': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "model = HistGradientBoostingRegressor()\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Optimize for negative MSE\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"\\nEvaluation Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R2 Score: {r2}\")\n",
    "\n",
    "# Save the best regressor model\n",
    "regressor_model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Conclusions & Accuracies\n",
    "I didn’t manage to create an accurate model by any stretch, but I’ve made progress in getting something functional. The models are far from perfect, with high error rates and low predictive power, but they do provide a starting point. The goal was to get to a point where I can move forward with building the app, and that’s where things stand now. The next step is to get the app up and running, with the understanding that these models will need serious refinement down the road. For now, the focus is on deployment and improving the models as I continue.\n",
    "\n",
    "#### Regressor (Crime Likelihood)\n",
    "```\n",
    "Mean Squared Error (MSE): 0.12060748392795712\n",
    "Root Mean Squared Error (RMSE): 0.3472858821316483\n",
    "Mean Absolute Error (MAE): 0.15950891086751307\n",
    "R2 Score: 0.047819078295898376\n",
    "```\n",
    "The regressor model isn’t performing great with a low R2 score, meaning it’s not explaining much of the variance in crime likelihood. The MSE is okay, but the RMSE shows that the predictions are a bit off from the actual values. The MAE tells us that, on average, the model is off by about 0.16. With the R2 score being low, there’s definitely room for improvement in future iterations. We’ll need better features or model tweaks to improve accuracy.\n",
    "\n",
    "\n",
    "#### Classifier (Crime Type)\n",
    "```\n",
    "Precision (weighted): 0.19163135273035\n",
    "Recall (weighted): 0.22740125530970645\n",
    "F1 Score (weighted): 0.16102398498675685\n",
    "Root Mean Squared Error (RMSE): 71.35365588711969\n",
    "```\n",
    "\n",
    "The classifier is struggling with low precision and recall, which means it’s not accurately identifying crime types. The F1 score reflects this imbalance, showing room for improvement. The RMSE also shows there’s quite a bit of error in the predictions. This model definitely needs some work to get more reliable results. For now, it gets the job done, but it’s far from optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models and Related Data to Files\n",
    "For use in the production environment. In this section, we're saving our trained models and encoders using `pickle` so they can be easily loaded into the Flask web app later. By serializing the `likelihood_regressor_model`, `type_classifier_model`, and `type_classifier_encoder` into files, we ensure that the models are ready for deployment. These files are stored in the `artifacts` folder, making it simple to load them into the Flask app when it’s running. This way, we can make predictions in real-time without needing to retrain the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('artifacts/likelihood_regressor_model.pkl', 'wb') as file:\n",
    "    pickle.dump(regressor_model, file)\n",
    "\n",
    "with open('artifacts/type_classifier_model.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier_model, file)\n",
    "\n",
    "with open('artifacts/type_classifier_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>OFFENSE_ID</th>\n",
       "      <th>OFFENSE_CODE</th>\n",
       "      <th>OFFENSE_CODE_EXTENSION</th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>OFFENSE_CATEGORY_ID</th>\n",
       "      <th>FIRST_OCCURRENCE_DATE</th>\n",
       "      <th>LAST_OCCURRENCE_DATE</th>\n",
       "      <th>REPORTED_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "      <th>DISTRICT_ID</th>\n",
       "      <th>PRECINCT_ID</th>\n",
       "      <th>NEIGHBORHOOD_ID</th>\n",
       "      <th>IS_CRIME</th>\n",
       "      <th>IS_TRAFFIC</th>\n",
       "      <th>VICTIM_COUNT</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2020467360</td>\n",
       "      <td>2020467360299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>8/2/2020 10:43:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/2/2020 10:43:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.024597</td>\n",
       "      <td>39.689751</td>\n",
       "      <td>4</td>\n",
       "      <td>422</td>\n",
       "      <td>ruby-hill</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.133789e+06</td>\n",
       "      <td>1.676471e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>20196003434</td>\n",
       "      <td>20196003434299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>4/20/2019 7:30:00 AM</td>\n",
       "      <td>4/20/2019 8:45:00 AM</td>\n",
       "      <td>4/20/2019 6:30:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.987348</td>\n",
       "      <td>39.714316</td>\n",
       "      <td>3</td>\n",
       "      <td>311</td>\n",
       "      <td>speer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.144221e+06</td>\n",
       "      <td>1.685476e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>2020123049</td>\n",
       "      <td>2020123049299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>2/25/2020 11:30:00 PM</td>\n",
       "      <td>2/26/2020 6:45:00 AM</td>\n",
       "      <td>2/26/2020 7:30:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.988098</td>\n",
       "      <td>39.764528</td>\n",
       "      <td>6</td>\n",
       "      <td>612</td>\n",
       "      <td>five-points</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.143907e+06</td>\n",
       "      <td>1.703765e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>2021621685</td>\n",
       "      <td>2021621685299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>11/1/2021 6:20:00 AM</td>\n",
       "      <td>11/1/2021 6:30:00 AM</td>\n",
       "      <td>11/1/2021 10:15:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.004665</td>\n",
       "      <td>39.739669</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>lincoln-park</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.139299e+06</td>\n",
       "      <td>1.694684e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>2020289138</td>\n",
       "      <td>2020289138299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>5/9/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/11/2020 12:05:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.830661</td>\n",
       "      <td>39.795281</td>\n",
       "      <td>5</td>\n",
       "      <td>521</td>\n",
       "      <td>montbello</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.188083e+06</td>\n",
       "      <td>1.715255e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  INCIDENT_ID         OFFENSE_ID  OFFENSE_CODE  \\\n",
       "0     20000   2020467360   2020467360299901          2999   \n",
       "1     20001  20196003434  20196003434299901          2999   \n",
       "2     20002   2020123049   2020123049299901          2999   \n",
       "3     20003   2021621685   2021621685299901          2999   \n",
       "4     20004   2020289138   2020289138299901          2999   \n",
       "\n",
       "   OFFENSE_CODE_EXTENSION            OFFENSE_TYPE_ID OFFENSE_CATEGORY_ID  \\\n",
       "0                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "1                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "2                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "3                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "4                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "\n",
       "   FIRST_OCCURRENCE_DATE  LAST_OCCURRENCE_DATE          REPORTED_DATE  ...  \\\n",
       "0   8/2/2020 10:43:00 PM                   NaN   8/2/2020 10:43:00 PM  ...   \n",
       "1   4/20/2019 7:30:00 AM  4/20/2019 8:45:00 AM   4/20/2019 6:30:00 PM  ...   \n",
       "2  2/25/2020 11:30:00 PM  2/26/2020 6:45:00 AM   2/26/2020 7:30:00 AM  ...   \n",
       "3   11/1/2021 6:20:00 AM  11/1/2021 6:30:00 AM  11/1/2021 10:15:00 AM  ...   \n",
       "4   5/9/2020 12:00:00 PM                   NaN  5/11/2020 12:05:00 PM  ...   \n",
       "\n",
       "      GEO_LON    GEO_LAT  DISTRICT_ID  PRECINCT_ID  NEIGHBORHOOD_ID IS_CRIME  \\\n",
       "0 -105.024597  39.689751            4          422        ruby-hill        1   \n",
       "1 -104.987348  39.714316            3          311            speer        1   \n",
       "2 -104.988098  39.764528            6          612      five-points        1   \n",
       "3 -105.004665  39.739669            1          123     lincoln-park        1   \n",
       "4 -104.830661  39.795281            5          521        montbello        1   \n",
       "\n",
       "   IS_TRAFFIC VICTIM_COUNT             x             y  \n",
       "0           0            1  3.133789e+06  1.676471e+06  \n",
       "1           0            1  3.144221e+06  1.685476e+06  \n",
       "2           0            1  3.143907e+06  1.703765e+06  \n",
       "3           0            1  3.139299e+06  1.694684e+06  \n",
       "4           0            1  3.188083e+06  1.715255e+06  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 394736 records!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import math\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Find all crime data CSV files matching the naming pattern\n",
    "csv_files = glob.glob(\"data/crime_split_*.csv\")\n",
    "\n",
    "# Read in all of the files and create Pandas dataframes from them\n",
    "split_dfs = [pd.read_csv(f) for f in csv_files]\n",
    "\n",
    "# Concatenate all the dataframes into a single one\n",
    "df = pd.concat(split_dfs, ignore_index=True)\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "original_dataframe_shape = df.shape\n",
    "print(f'Loaded {original_dataframe_shape[0]} records!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFFENSE_CATEGORY_ID:\n",
      " * public-disorder\n",
      " * drug-alcohol\n",
      " * theft-from-motor-vehicle\n",
      " * larceny\n",
      " * other-crimes-against-persons\n",
      " * all-other-crimes\n",
      " * murder\n",
      " * robbery\n",
      " * aggravated-assault\n",
      " * arson\n",
      " * burglary\n",
      " * auto-theft\n",
      " * white-collar-crime\n",
      "\n",
      "OFFENSE_TYPE_ID:\n",
      " * criminal-mischief-mtr-veh\n",
      " * criminal-mischief-graffiti\n",
      " * drug-hallucinogen-mfr\n",
      " * drug-hallucinogen-sell\n",
      " * drug-hallucinogen-possess\n",
      " * drug-heroin-sell\n",
      " * drug-heroin-possess\n",
      " * theft-items-from-vehicle\n",
      " * burglary-vending-machine\n",
      " * theft-from-bldg\n",
      " * drug-opium-or-deriv-sell\n",
      " * drug-opium-or-deriv-possess\n",
      " * drug-cocaine-sell\n",
      " * drug-cocaine-possess\n",
      " * drug-synth-narcotic-sell\n",
      " * drug-synth-narcotic-possess\n",
      " * drug-poss-paraphernalia\n",
      " * drug-marijuana-sell\n",
      " * drug-marijuana-possess\n",
      " * drug-marijuana-cultivation\n",
      " * drug-methamphetamine-mfr\n",
      " * drug-methampetamine-sell\n",
      " * drug-methampetamine-possess\n",
      " * drug-barbiturate-mfr\n",
      " * drug-barbiturate-sell\n",
      " * drug-barbiturate-possess\n",
      " * drug-pcs-other-drug\n",
      " * drug-make-sell-other-drug\n",
      " * indecent-exposure\n",
      " * window-peeping\n",
      " * sex-off-fail-to-register\n",
      " * criminal-mischief-other\n",
      " * police-resisting-arrest\n",
      " * police-false-information\n",
      " * police-interference\n",
      " * violation-of-restraining-order\n",
      " * violation-of-court-order\n",
      " * weapon-by-prev-offender-powpo\n",
      " * weapon-unlawful-discharge-of\n",
      " * weapon-flourishing\n",
      " * weapon-other-viol\n",
      " * harassment\n",
      " * harassment-dv\n",
      " * public-fighting\n",
      " * disturbing-the-peace\n",
      " * criminal-trespassing\n",
      " * public-order-crimes-other\n",
      " * homicide-other\n",
      " * false-imprisonment\n",
      " * robbery-business\n",
      " * robbery-street\n",
      " * assault-simple\n",
      " * assault-dv\n",
      " * weapon-fire-into-occ-veh\n",
      " * aggravated-assault\n",
      " * aggravated-assault-dv\n",
      " * menacing-felony-w-weap\n",
      " * threats-to-injure\n",
      " * arson-residence\n",
      " * extortion\n",
      " * burglary-residence-by-force\n",
      " * burglary-business-by-force\n",
      " * burglary-residence-no-force\n",
      " * burg-auto-theft-resd-no-force\n",
      " * burglary-business-no-force\n",
      " * theft-shoplift\n",
      " * theft-parts-from-vehicle\n",
      " * theft-other\n",
      " * theft-bicycle\n",
      " * theft-stln-vehicle-trailer\n",
      " * theft-of-motor-vehicle\n",
      " * theft-unauth-use-of-ftd\n",
      " * fraud-nsf-closed-account\n",
      " * fraud-by-telephone\n",
      " * fraud-by-use-of-computer\n",
      " * theft-of-services\n",
      " * theft-embezzle\n",
      " * agg-aslt-shoot\n",
      " * weapon-poss-illegal-dangerous\n",
      " * contraband-into-prison\n",
      " * kidnap-adult-victim\n",
      " * robbery-purse-snatch-w-force\n",
      " * robbery-car-jacking\n",
      " * arson-vehicle\n",
      " * burg-auto-theft-busn-w-force\n",
      " * burglary-poss-of-tools\n",
      " * theft-from-mails\n",
      " * forgery-checks\n",
      " * weapon-fire-into-occ-bldg\n",
      " * harassment-stalking-dv\n",
      " * burglary-safe\n",
      " * theft-fail-return-rent-veh\n",
      " * obstructing-govt-operation\n",
      " * assault-police-simple\n",
      " * prostitution-engaging-in\n",
      " * bribery\n",
      " * kidnap-dv\n",
      " * robbery-residence\n",
      " * theft-pick-pocket\n",
      " * forgery-counterfeit-of-obj\n",
      " * obscene-material-possess\n",
      " * violation-of-custody-order\n",
      " * arson-other\n",
      " * fraud-criminal-impersonation\n",
      " * stolen-property-buy-sell-rec\n",
      " * public-peace-other\n",
      " * burg-auto-theft-busn-no-force\n",
      " * theft-stln-veh-const-eqpt\n",
      " * liquor-sell\n",
      " * robbery-bank\n",
      " * theft-purse-snatch-no-force\n",
      " * forgery-poss-of-forged-inst\n",
      " * liquor-possession\n",
      " * curfew\n",
      " * weapon-carrying-prohibited\n",
      " * theft-of-rental-property\n",
      " * bomb-threat\n",
      " * aslt-agg-police-gun\n",
      " * weapon-carrying-concealed\n",
      " * accessory-conspiracy-to-crime\n",
      " * theft-confidence-game\n",
      " * property-crimes-other\n",
      " * arson-business\n",
      " * escape\n",
      " * forgery-other\n",
      " * littering\n",
      " * illegal-dumping\n",
      " * theft-gas-drive-off\n",
      " * explosive-incendiary-dev-use\n",
      " * police-obstruct-investigation\n",
      " * reckless-endangerment\n",
      " * intimidation-of-a-witness\n",
      " * agg-aslt-police-weapon\n",
      " * burg-auto-theft-resd-w-force\n",
      " * contraband-possession\n",
      " * homicide-negligent\n",
      " * police-making-a-false-rpt\n",
      " * forgery-poss-of-forged-ftd\n",
      " * impersonation-of-police\n",
      " * police-disobey-lawful-order\n",
      " * animal-cruelty-to\n",
      " * drug-fraud-to-obtain\n",
      " * pawn-broker-viol\n",
      " * loitering\n",
      " * animal-poss-of-dangerous\n",
      " * arson-public-building\n",
      " * sex-off-registration-viol\n",
      " * obscene-material-mfr\n",
      " * bigamy\n",
      " * gambling-betting-wagering\n",
      " * gambling-gaming-operation\n",
      " * prostitution-pimping\n",
      " * prostitution-aiding\n",
      " * liquor-manufacturing\n",
      " * escape-aiding\n",
      " * parole-violation\n",
      " * probation-violation\n",
      " * weapon-altering-serial-number\n",
      " * explosive-incendiary-dev-pos\n",
      " * burglary-other\n",
      " * forgery-posses-forge-device\n",
      " * weapon-unlawful-sale\n",
      " * homicide-family\n",
      " * disarming-a-peace-officer\n",
      " * fireworks-possession\n",
      " * homicide-police-by-gun\n",
      " * riot-incite\n",
      " * wiretapping\n",
      " * other-enviornment-animal-viol\n",
      " * money-laundering\n",
      " * eavesdropping\n",
      " * homicide-accessory-to\n",
      " * homicide-solicitation\n",
      " * theft-of-cable-services\n",
      " * altering-vin-number\n",
      " * drug-forgery-to-obtain\n",
      " * fraud-identity-theft\n",
      " * theft-from-yards\n"
     ]
    }
   ],
   "source": [
    "print('OFFENSE_CATEGORY_ID:\\n * ' + '\\n * '.join(df['OFFENSE_CATEGORY_ID'].unique()))\n",
    "print()\n",
    "print('OFFENSE_TYPE_ID:\\n * ' + '\\n * '.join(df['OFFENSE_TYPE_ID'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the issue was too many categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CATEGORY_ID</th>\n",
       "      <th>FIRST_OCCURRENCE_DATE</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318029</th>\n",
       "      <td>larceny</td>\n",
       "      <td>7/26/2020 3:00:00 AM</td>\n",
       "      <td>-104.980216</td>\n",
       "      <td>39.743887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391216</th>\n",
       "      <td>aggravated-assault</td>\n",
       "      <td>3/10/2023 4:00:00 PM</td>\n",
       "      <td>-105.061707</td>\n",
       "      <td>39.654226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15606</th>\n",
       "      <td>theft-from-motor-vehicle</td>\n",
       "      <td>2/6/2021 4:10:00 PM</td>\n",
       "      <td>-105.029968</td>\n",
       "      <td>39.700087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62207</th>\n",
       "      <td>public-disorder</td>\n",
       "      <td>9/20/2019 10:15:00 PM</td>\n",
       "      <td>-104.941432</td>\n",
       "      <td>39.708120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296025</th>\n",
       "      <td>theft-from-motor-vehicle</td>\n",
       "      <td>8/20/2023 7:00:00 PM</td>\n",
       "      <td>-104.946670</td>\n",
       "      <td>39.665493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149324</th>\n",
       "      <td>burglary</td>\n",
       "      <td>8/5/2022 12:00:00 AM</td>\n",
       "      <td>-104.909416</td>\n",
       "      <td>39.775094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125614</th>\n",
       "      <td>larceny</td>\n",
       "      <td>9/14/2024 4:00:00 PM</td>\n",
       "      <td>-104.982543</td>\n",
       "      <td>39.726770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325728</th>\n",
       "      <td>larceny</td>\n",
       "      <td>7/11/2021 7:30:00 AM</td>\n",
       "      <td>-104.903154</td>\n",
       "      <td>39.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68472</th>\n",
       "      <td>public-disorder</td>\n",
       "      <td>7/7/2021 7:45:00 PM</td>\n",
       "      <td>-105.049997</td>\n",
       "      <td>39.741312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237259</th>\n",
       "      <td>other-crimes-against-persons</td>\n",
       "      <td>11/6/2020 11:03:00 AM</td>\n",
       "      <td>-104.977850</td>\n",
       "      <td>39.744989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29468</th>\n",
       "      <td>larceny</td>\n",
       "      <td>3/29/2020 9:57:00 AM</td>\n",
       "      <td>-104.674045</td>\n",
       "      <td>39.851926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146382</th>\n",
       "      <td>burglary</td>\n",
       "      <td>2/27/2020 10:57:00 PM</td>\n",
       "      <td>-105.024547</td>\n",
       "      <td>39.666133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306886</th>\n",
       "      <td>all-other-crimes</td>\n",
       "      <td>11/6/2022 2:15:00 AM</td>\n",
       "      <td>-105.001799</td>\n",
       "      <td>39.740275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349715</th>\n",
       "      <td>theft-from-motor-vehicle</td>\n",
       "      <td>7/14/2023 10:30:00 PM</td>\n",
       "      <td>-104.984649</td>\n",
       "      <td>39.752695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78491</th>\n",
       "      <td>public-disorder</td>\n",
       "      <td>5/19/2021 3:30:00 PM</td>\n",
       "      <td>-104.980203</td>\n",
       "      <td>39.724915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54442</th>\n",
       "      <td>theft-from-motor-vehicle</td>\n",
       "      <td>5/18/2019 12:00:00 AM</td>\n",
       "      <td>-104.933417</td>\n",
       "      <td>39.746510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173471</th>\n",
       "      <td>theft-from-motor-vehicle</td>\n",
       "      <td>1/1/2020 5:30:00 PM</td>\n",
       "      <td>-105.025476</td>\n",
       "      <td>39.721106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388883</th>\n",
       "      <td>burglary</td>\n",
       "      <td>2/24/2023 8:25:00 PM</td>\n",
       "      <td>-104.975478</td>\n",
       "      <td>39.735392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>public-disorder</td>\n",
       "      <td>10/27/2020 9:45:00 AM</td>\n",
       "      <td>-104.924126</td>\n",
       "      <td>39.695584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153721</th>\n",
       "      <td>burglary</td>\n",
       "      <td>7/31/2020 4:00:00 AM</td>\n",
       "      <td>-105.029600</td>\n",
       "      <td>39.691943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 OFFENSE_CATEGORY_ID  FIRST_OCCURRENCE_DATE     GEO_LON  \\\n",
       "318029                       larceny   7/26/2020 3:00:00 AM -104.980216   \n",
       "391216            aggravated-assault   3/10/2023 4:00:00 PM -105.061707   \n",
       "15606       theft-from-motor-vehicle    2/6/2021 4:10:00 PM -105.029968   \n",
       "62207                public-disorder  9/20/2019 10:15:00 PM -104.941432   \n",
       "296025      theft-from-motor-vehicle   8/20/2023 7:00:00 PM -104.946670   \n",
       "149324                      burglary   8/5/2022 12:00:00 AM -104.909416   \n",
       "125614                       larceny   9/14/2024 4:00:00 PM -104.982543   \n",
       "325728                       larceny   7/11/2021 7:30:00 AM -104.903154   \n",
       "68472                public-disorder    7/7/2021 7:45:00 PM -105.049997   \n",
       "237259  other-crimes-against-persons  11/6/2020 11:03:00 AM -104.977850   \n",
       "29468                        larceny   3/29/2020 9:57:00 AM -104.674045   \n",
       "146382                      burglary  2/27/2020 10:57:00 PM -105.024547   \n",
       "306886              all-other-crimes   11/6/2022 2:15:00 AM -105.001799   \n",
       "349715      theft-from-motor-vehicle  7/14/2023 10:30:00 PM -104.984649   \n",
       "78491                public-disorder   5/19/2021 3:30:00 PM -104.980203   \n",
       "54442       theft-from-motor-vehicle  5/18/2019 12:00:00 AM -104.933417   \n",
       "173471      theft-from-motor-vehicle    1/1/2020 5:30:00 PM -105.025476   \n",
       "388883                      burglary   2/24/2023 8:25:00 PM -104.975478   \n",
       "2529                 public-disorder  10/27/2020 9:45:00 AM -104.924126   \n",
       "153721                      burglary   7/31/2020 4:00:00 AM -105.029600   \n",
       "\n",
       "          GEO_LAT  \n",
       "318029  39.743887  \n",
       "391216  39.654226  \n",
       "15606   39.700087  \n",
       "62207   39.708120  \n",
       "296025  39.665493  \n",
       "149324  39.775094  \n",
       "125614  39.726770  \n",
       "325728  39.654000  \n",
       "68472   39.741312  \n",
       "237259  39.744989  \n",
       "29468   39.851926  \n",
       "146382  39.666133  \n",
       "306886  39.740275  \n",
       "349715  39.752695  \n",
       "78491   39.724915  \n",
       "54442   39.746510  \n",
       "173471  39.721106  \n",
       "388883  39.735392  \n",
       "2529    39.695584  \n",
       "153721  39.691943  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep only the columns that we want\n",
    "df = df[['OFFENSE_CATEGORY_ID','FIRST_OCCURRENCE_DATE','GEO_LON','GEO_LAT']]\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CATEGORY_ID</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>HOUR_COS</th>\n",
       "      <th>HOUR_SIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>375083</th>\n",
       "      <td>drug-alcohol</td>\n",
       "      <td>-105.055325</td>\n",
       "      <td>39.734441</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>335</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296432</th>\n",
       "      <td>auto-theft</td>\n",
       "      <td>-104.983265</td>\n",
       "      <td>39.737353</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382390</th>\n",
       "      <td>public-disorder</td>\n",
       "      <td>-104.936108</td>\n",
       "      <td>39.747067</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>355</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181253</th>\n",
       "      <td>larceny</td>\n",
       "      <td>-104.903129</td>\n",
       "      <td>39.720011</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>281</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73633</th>\n",
       "      <td>public-disorder</td>\n",
       "      <td>-104.973226</td>\n",
       "      <td>39.727497</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OFFENSE_CATEGORY_ID     GEO_LON    GEO_LAT  YEAR  DAY_OF_WEEK  \\\n",
       "375083        drug-alcohol -105.055325  39.734441  2023            4   \n",
       "296432          auto-theft -104.983265  39.737353  2023            0   \n",
       "382390     public-disorder -104.936108  39.747067  2023            3   \n",
       "181253             larceny -104.903129  39.720011  2020            2   \n",
       "73633      public-disorder -104.973226  39.727497  2022            2   \n",
       "\n",
       "        DAY_OF_YEAR  HOUR_COS  HOUR_SIN  \n",
       "375083          335  0.258819 -0.965926  \n",
       "296432          233 -0.258819 -0.965926  \n",
       "382390          355 -0.707107 -0.707107  \n",
       "181253          281 -0.258819 -0.965926  \n",
       "73633           236 -0.707107 -0.707107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert FIRST_OCCURRENCE_DATE to Pandas date time format\n",
    "df['FIRST_OCCURRENCE_DATE'] = pd.to_datetime(df['FIRST_OCCURRENCE_DATE'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# Extract date and time components\n",
    "df['YEAR'] = df['FIRST_OCCURRENCE_DATE'].dt.year\n",
    "df['DAY_OF_WEEK'] = df['FIRST_OCCURRENCE_DATE'].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "df['DAY_OF_YEAR'] = df['FIRST_OCCURRENCE_DATE'].dt.dayofyear\n",
    "df['HOUR_COS'] = np.cos(2 * np.pi * df['FIRST_OCCURRENCE_DATE'].dt.hour / 24) # Learned that some models interpret hour 0 and \n",
    "df['HOUR_SIN'] = np.sin(2 * np.pi * df['FIRST_OCCURRENCE_DATE'].dt.hour / 24) #   hour 23 as far apart even though they are together. Sin/Cos make continuous.\n",
    "\n",
    "# Finally, dropping the FIRST_OCCURRENCE_DATE column\n",
    "df.drop(columns=['FIRST_OCCURRENCE_DATE'], inplace=True)\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size before removal: 394736 items\n",
      "Dataframe size after removal: 394475 items\n",
      "--> 261 items removed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CATEGORY_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>HOUR_COS</th>\n",
       "      <th>HOUR_SIN</th>\n",
       "      <th>X_BLOCK</th>\n",
       "      <th>Y_BLOCK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>389490</th>\n",
       "      <td>murder</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>10236</td>\n",
       "      <td>87797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108706</th>\n",
       "      <td>burglary</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>171</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>10106</td>\n",
       "      <td>87961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32753</th>\n",
       "      <td>drug-alcohol</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>281</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>10019</td>\n",
       "      <td>87859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33987</th>\n",
       "      <td>drug-alcohol</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>308</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9995</td>\n",
       "      <td>88011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332303</th>\n",
       "      <td>larceny</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>247</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>10055</td>\n",
       "      <td>87993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OFFENSE_CATEGORY_ID  YEAR  DAY_OF_WEEK  DAY_OF_YEAR  HOUR_COS  \\\n",
       "389490              murder  2023            3           61  0.965926   \n",
       "108706            burglary  2021            6          171  0.965926   \n",
       "32753         drug-alcohol  2019            1          281 -0.965926   \n",
       "33987         drug-alcohol  2021            3          308 -0.866025   \n",
       "332303             larceny  2020            3          247 -0.965926   \n",
       "\n",
       "        HOUR_SIN  X_BLOCK  Y_BLOCK  \n",
       "389490  0.258819    10236    87797  \n",
       "108706 -0.258819    10106    87961  \n",
       "32753   0.258819    10019    87859  \n",
       "33987   0.500000     9995    88011  \n",
       "332303 -0.258819    10055    87993  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before location outlier removal: 394475 records.\n",
      "Size after location outlier removal: 394434 records.\n",
      "--> 41 records removed!\n"
     ]
    }
   ],
   "source": [
    "GRID_SIZE = 50\n",
    "\n",
    "# Initialize UTM projection (assuming UTM Zone 13N for Denver)\n",
    "#   https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system\n",
    "#   https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system#/media/File:Universal_Transverse_Mercator_zones.svg\n",
    "utm_proj = pyproj.Proj(proj=\"utm\", zone=13, datum=\"WGS84\")\n",
    "\n",
    "def get_grid_block(lat, lon):\n",
    "    try:\n",
    "        # Convert latitude and longitude to UTM coordinates (X, Y)\n",
    "        x, y = utm_proj(lon, lat)  # Correct order: lon, lat\n",
    "        \n",
    "        # Calculate the X and Y blocks\n",
    "        x_block = int(x // GRID_SIZE)\n",
    "        y_block = int(y // GRID_SIZE)\n",
    "        \n",
    "        return x_block, y_block\n",
    "    except:\n",
    "        # If there is an issue parsing, return -1\n",
    "        return -1, -1\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['X_BLOCK', 'Y_BLOCK']] = df.apply(lambda row: get_grid_block(row['GEO_LAT'], row['GEO_LON']), axis=1, result_type='expand')\n",
    "\n",
    "# Drop rows where X_BLOCK or Y_BLOCK is -1\n",
    "df = df[(df['X_BLOCK'] != -1) & (df['Y_BLOCK'] != -1)]\n",
    "\n",
    "# Note change in size\n",
    "post_null_geo_block_removal_dataframe_shape = df.shape\n",
    "print(f'Dataframe size before removal: {original_dataframe_shape[0]} items')\n",
    "print(f'Dataframe size after removal: {post_null_geo_block_removal_dataframe_shape[0]} items')\n",
    "print(f'--> {original_dataframe_shape[0] - post_null_geo_block_removal_dataframe_shape[0]} items removed!')\n",
    "\n",
    "# Finally, dropping the GEO_LAT and GEO_LON columns since we have replaced them with X_BLOCK and Y_BLOCK\n",
    "df.drop(columns=['GEO_LAT'], inplace=True)\n",
    "df.drop(columns=['GEO_LON'], inplace=True)\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=5))\n",
    "\n",
    "df_shape_before_location_outlier_drop = df.shape\n",
    "\n",
    "Q1 = df['X_BLOCK'].quantile(0.01)\n",
    "Q3 = df['X_BLOCK'].quantile(0.99)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df.loc[(df['X_BLOCK'] >= lower_bound) & (df['X_BLOCK'] <= upper_bound)]\n",
    "\n",
    "# Calculate and display rows removed\n",
    "df_shape_after_location_outlier_drop = df.shape\n",
    "print(f'Size before location outlier removal: {df_shape_before_location_outlier_drop[0]} records.')\n",
    "print(f'Size after location outlier removal: {df_shape_after_location_outlier_drop[0]} records.')\n",
    "print(f'--> {df_shape_before_location_outlier_drop[0] - df_shape_after_location_outlier_drop[0]} records removed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CATEGORY_ID</th>\n",
       "      <th>X_BLOCK</th>\n",
       "      <th>Y_BLOCK</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>HOUR_SIN</th>\n",
       "      <th>HOUR_COS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50560</th>\n",
       "      <td>theft-from-motor-vehicle</td>\n",
       "      <td>9947</td>\n",
       "      <td>87864</td>\n",
       "      <td>2019</td>\n",
       "      <td>360</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83930</th>\n",
       "      <td>theft-from-motor-vehicle</td>\n",
       "      <td>10035</td>\n",
       "      <td>87954</td>\n",
       "      <td>2019</td>\n",
       "      <td>319</td>\n",
       "      <td>4</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>9.659258e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289068</th>\n",
       "      <td>aggravated-assault</td>\n",
       "      <td>10167</td>\n",
       "      <td>87979</td>\n",
       "      <td>2022</td>\n",
       "      <td>286</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303506</th>\n",
       "      <td>larceny</td>\n",
       "      <td>10185</td>\n",
       "      <td>88069</td>\n",
       "      <td>2023</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278797</th>\n",
       "      <td>all-other-crimes</td>\n",
       "      <td>10060</td>\n",
       "      <td>87979</td>\n",
       "      <td>2024</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             OFFENSE_CATEGORY_ID  X_BLOCK  Y_BLOCK  YEAR  DAY_OF_YEAR  \\\n",
       "50560   theft-from-motor-vehicle     9947    87864  2019          360   \n",
       "83930   theft-from-motor-vehicle    10035    87954  2019          319   \n",
       "289068        aggravated-assault    10167    87979  2022          286   \n",
       "303506                   larceny    10185    88069  2023          275   \n",
       "278797          all-other-crimes    10060    87979  2024          101   \n",
       "\n",
       "        DAY_OF_WEEK  HOUR_SIN      HOUR_COS  \n",
       "50560             3 -0.500000  8.660254e-01  \n",
       "83930             4  0.258819  9.659258e-01  \n",
       "289068            3 -0.965926 -2.588190e-01  \n",
       "303506            0 -1.000000 -1.836970e-16  \n",
       "278797            2 -0.965926 -2.588190e-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reorder columns\n",
    "df = df[[\n",
    "    'OFFENSE_CATEGORY_ID',\n",
    "    'X_BLOCK',\n",
    "    'Y_BLOCK',\n",
    "    'YEAR',\n",
    "    'DAY_OF_YEAR',\n",
    "    'DAY_OF_WEEK',\n",
    "    'HOUR_SIN',\n",
    "    'HOUR_COS',\n",
    "]]\n",
    "display(df.sample(n=5))\n",
    "original_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Best Parameters: {'l2_regularization': 0, 'learning_rate': 0.1, 'max_depth': 7, 'max_iter': 200, 'min_samples_leaf': 20}\n",
      "\n",
      "Evaluation Metrics:\n",
      "Mean Squared Error (MSE): 0.10421870655349885\n",
      "Root Mean Squared Error (RMSE): 0.32282922196340724\n",
      "Mean Absolute Error (MAE): 0.14820025331663794\n",
      "R2 Score: 0.030293926173318053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Group by grid cell, day of year, and hour to count crimes\n",
    "crime_counts = df.groupby(['X_BLOCK', 'Y_BLOCK', 'YEAR', 'DAY_OF_YEAR', 'DAY_OF_WEEK', 'HOUR_SIN', 'HOUR_COS']).size().reset_index(name='CRIME_COUNT')\n",
    "\n",
    "# Features and target\n",
    "X = crime_counts[['X_BLOCK', 'Y_BLOCK', 'YEAR', 'DAY_OF_YEAR', 'DAY_OF_WEEK', 'HOUR_SIN', 'HOUR_COS']]\n",
    "y = crime_counts['CRIME_COUNT']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_depth': [7],\n",
    "    'l2_regularization': [0, 0.01, 0.1],\n",
    "    'min_samples_leaf': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Initialize the base model\n",
    "model = HistGradientBoostingRegressor()\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',  # Optimize for negative MSE\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\nBest Parameters:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"\\nEvaluation Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R2 Score: {r2}\")\n",
    "\n",
    "# Save the best regressor model\n",
    "regressor_model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Distribution:\n",
      " OFFENSE_CATEGORY_ID\n",
      "11    53142\n",
      "3     48311\n",
      "9     47696\n",
      "6     46435\n",
      "1     37364\n",
      "4     22891\n",
      "8     16838\n",
      "5     16142\n",
      "0     14663\n",
      "10     5645\n",
      "12     5403\n",
      "2       682\n",
      "7       335\n",
      "Name: count, dtype: int64\n",
      "Test Class Distribution:\n",
      " OFFENSE_CATEGORY_ID\n",
      "11    13285\n",
      "3     12078\n",
      "9     11924\n",
      "6     11609\n",
      "1      9341\n",
      "4      5723\n",
      "8      4209\n",
      "5      4036\n",
      "0      3666\n",
      "10     1411\n",
      "12     1351\n",
      "2       170\n",
      "7        84\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.28638432187812946\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.00      0.01      3666\n",
      "           1       0.30      0.36      0.33      9341\n",
      "           2       0.02      0.03      0.02       170\n",
      "           3       0.28      0.41      0.33     12078\n",
      "           4       0.36      0.09      0.15      5723\n",
      "           5       0.44      0.35      0.39      4036\n",
      "           6       0.34      0.40      0.36     11609\n",
      "           7       0.00      0.00      0.00        84\n",
      "           8       0.37      0.06      0.10      4209\n",
      "           9       0.20      0.14      0.17     11924\n",
      "          10       0.05      0.00      0.00      1411\n",
      "          11       0.27      0.43      0.33     13285\n",
      "          12       0.37      0.05      0.09      1351\n",
      "\n",
      "    accuracy                           0.29     78887\n",
      "   macro avg       0.24      0.18      0.17     78887\n",
      "weighted avg       0.29      0.29      0.26     78887\n",
      "\n",
      "Precision (weighted): 0.2863567980346278\n",
      "Recall (weighted): 0.28638432187812946\n",
      "F1 Score (weighted): 0.26120728152142597\n",
      "Root Mean Squared Error (RMSE): 4.750856661203363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "df['OFFENSE_CATEGORY_ID'] = encoder.fit_transform(df['OFFENSE_CATEGORY_ID'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('OFFENSE_CATEGORY_ID', axis=1)\n",
    "y = df['OFFENSE_CATEGORY_ID']\n",
    "\n",
    "# Remove rare classes with only 1 instance\n",
    "class_counts = y.value_counts()\n",
    "rare_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "# Filter out the rare classes from the dataset\n",
    "filtered_df = df[~df['OFFENSE_CATEGORY_ID'].isin(rare_classes)]\n",
    "\n",
    "# Update X and y after removing rare classes\n",
    "X = filtered_df.drop('OFFENSE_CATEGORY_ID', axis=1)\n",
    "y = filtered_df['OFFENSE_CATEGORY_ID']\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Ensure no class is left with fewer than 2 members in either train or test\n",
    "train_class_counts = y_train.value_counts()\n",
    "test_class_counts = y_test.value_counts()\n",
    "\n",
    "# Print out the counts for train and test to debug\n",
    "print(\"Train Class Distribution:\\n\", train_class_counts)\n",
    "print(\"Test Class Distribution:\\n\", test_class_counts)\n",
    "\n",
    "# Check if any class is left with 1 sample in the train set\n",
    "if any(train_class_counts < 2):\n",
    "    print(\"Some classes in the train set have less than 2 samples. Consider further reducing or combining classes.\")\n",
    "else:\n",
    "    # Initialize and train the model\n",
    "    model = HistGradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Classification report (includes precision, recall, F1-score)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # Precision, Recall, and F1 Score\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    print(f\"Precision (weighted): {precision}\")\n",
    "    print(f\"Recall (weighted): {recall}\")\n",
    "    print(f\"F1 Score (weighted): {f1}\")\n",
    "\n",
    "    # RMSE (Root Mean Squared Error)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "    # To decode the predictions back to the original labels\n",
    "    decoded_predictions = encoder.inverse_transform(y_pred)\n",
    "\n",
    "    # Save the best classifier model\n",
    "    classifier_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No real improvement with changing of the grid size... abandoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('artifacts/50m_crime_count_model.pkl', 'wb') as file:\n",
    "    pickle.dump(regressor_model, file)\n",
    "\n",
    "with open('artifacts/50m_crime_type_model.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier_model, file)\n",
    "\n",
    "with open('artifacts/50m_crime_type_model_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
