{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denver Crime Heatmap Notebook\n",
    "CS 3120 Machine Learning Term Project - Konstantin Zaremski\n",
    "\n",
    "---\n",
    "\n",
    "This comprehensive notebook covers my project from ideation and planning, to exploratory data analysis (EDA), and final implementation.\n",
    "### *********** Unfinished Draft (for peer review)\n",
    "\n",
    "> ### Project Proposal\n",
    "> ##### Introduction & Description\n",
    "> After my car was vandalized in Denver earlier this October, I began ruminating on what makes an area “safe”. Eventually I came upon the Denver Public Crime Map which shows the 1000 most recent incidents on a map. This got me interested in the possibility of using this data in a predictive capacity. I am going to build a Denver crime prediction or likelihood map app, that will predict the likelihood of crime overall, predict the most likely crimes to be committed for different areas, and then present this as a heatmap visualization to the user.\n",
    "> \n",
    "> ##### Dataset\n",
    "> The source dataset for the public crime map is provided by Denver and contains 394,475 data points sourced from the FBI’s NIBRS database. After stripping off useless columns such as database keys and precinct numbers, the usable columns are the date and time of occurrence, type and category of crime, and longitude and latitude. Crimes do not happen because of a longitude and latitude value, so I am enriching the original dataset by adding additional features by querying each data point against Open Street Map data for land use, proximity to residential or main roads, building types, and amenities such as ATMs or RTD stations.\n",
    "> \n",
    "> ##### Model\n",
    "> I will be training two models to make predictions for my app: one model to enable the prediction of the total amount of crimes in an area given input features, and another model to perform multiclass classification to predict what type of crime is most likely to be committed in an area given input features. Since the input data and resulting crime or number of crimes is known and labeled, supervised learning models are best suited for this data. I will be using SciKit Learn’s HistGradientBoostingClassifier to predict crime type and HistGradientBoostingRegressor to predict crime volume. I am electing to use gradient boosting over decision trees or other models since it has a lower bias and should be more sensitive to different crime patterns.\n",
    "> \n",
    "> ##### App Functionality\n",
    "> The web app will be a simple map interface with a color heatmap overlay based on the underlying model’s crime predictions. The user will have options for a time delta, where they can view the heatmap/predictions for the current time plus or minus up to 48 hours. The user will have a way to toggle between seeing a multi-color heatmap for the types of crimes that are predicted, a single-color heatmap for the likelihood or predicted frequency of crime, and a heatmap that combines both, with areas having a lower predicted likelihood or frequency of crime being denoted by a more transparent version of the color representing the crime type for that area.\n",
    "> \n",
    "> ##### Technical Implementation\n",
    "> Since the app does not have user accounts, the backend can be implemented as a simple Flask app with an API endpoint to retrieve the heatmap overlay based on the map area the client says the user is currently viewing. Predictions will be stored in an SQLite database where they can be quickly retrieved to generate a heatmap at view time. The frontend will be implemented using simple HTML, CSS, and vanilla JavaScript to enable interactions. The map itself will be rendered using the Leaflet JavaScript map library/project.\n",
    "> \n",
    "> ##### Feasibility\n",
    "> Since the app itself is a visualization with only a few buttons/interactions, and no user accounts or user data collection, it will be simple to implement, which will allow for more time to be spent on tuning the models and finding the optimal way to slice the map or bin data.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis & Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Importing required modules and libraries for EDA, etc. See `requirements_eda.txt` for a full list of requirements to install into the environment using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import math\n",
    "import pyproj\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>INCIDENT_ID</th>\n",
       "      <th>OFFENSE_ID</th>\n",
       "      <th>OFFENSE_CODE</th>\n",
       "      <th>OFFENSE_CODE_EXTENSION</th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>OFFENSE_CATEGORY_ID</th>\n",
       "      <th>FIRST_OCCURRENCE_DATE</th>\n",
       "      <th>LAST_OCCURRENCE_DATE</th>\n",
       "      <th>REPORTED_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "      <th>DISTRICT_ID</th>\n",
       "      <th>PRECINCT_ID</th>\n",
       "      <th>NEIGHBORHOOD_ID</th>\n",
       "      <th>IS_CRIME</th>\n",
       "      <th>IS_TRAFFIC</th>\n",
       "      <th>VICTIM_COUNT</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2020467360</td>\n",
       "      <td>2020467360299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>8/2/2020 10:43:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/2/2020 10:43:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.024597</td>\n",
       "      <td>39.689751</td>\n",
       "      <td>4</td>\n",
       "      <td>422</td>\n",
       "      <td>ruby-hill</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.133789e+06</td>\n",
       "      <td>1.676471e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>20196003434</td>\n",
       "      <td>20196003434299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>4/20/2019 7:30:00 AM</td>\n",
       "      <td>4/20/2019 8:45:00 AM</td>\n",
       "      <td>4/20/2019 6:30:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.987348</td>\n",
       "      <td>39.714316</td>\n",
       "      <td>3</td>\n",
       "      <td>311</td>\n",
       "      <td>speer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.144221e+06</td>\n",
       "      <td>1.685476e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>2020123049</td>\n",
       "      <td>2020123049299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>2/25/2020 11:30:00 PM</td>\n",
       "      <td>2/26/2020 6:45:00 AM</td>\n",
       "      <td>2/26/2020 7:30:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.988098</td>\n",
       "      <td>39.764528</td>\n",
       "      <td>6</td>\n",
       "      <td>612</td>\n",
       "      <td>five-points</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.143907e+06</td>\n",
       "      <td>1.703765e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>2021621685</td>\n",
       "      <td>2021621685299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>11/1/2021 6:20:00 AM</td>\n",
       "      <td>11/1/2021 6:30:00 AM</td>\n",
       "      <td>11/1/2021 10:15:00 AM</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.004665</td>\n",
       "      <td>39.739669</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>lincoln-park</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.139299e+06</td>\n",
       "      <td>1.694684e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>2020289138</td>\n",
       "      <td>2020289138299901</td>\n",
       "      <td>2999</td>\n",
       "      <td>1</td>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>public-disorder</td>\n",
       "      <td>5/9/2020 12:00:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/11/2020 12:05:00 PM</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.830661</td>\n",
       "      <td>39.795281</td>\n",
       "      <td>5</td>\n",
       "      <td>521</td>\n",
       "      <td>montbello</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.188083e+06</td>\n",
       "      <td>1.715255e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  INCIDENT_ID         OFFENSE_ID  OFFENSE_CODE  \\\n",
       "0     20000   2020467360   2020467360299901          2999   \n",
       "1     20001  20196003434  20196003434299901          2999   \n",
       "2     20002   2020123049   2020123049299901          2999   \n",
       "3     20003   2021621685   2021621685299901          2999   \n",
       "4     20004   2020289138   2020289138299901          2999   \n",
       "\n",
       "   OFFENSE_CODE_EXTENSION            OFFENSE_TYPE_ID OFFENSE_CATEGORY_ID  \\\n",
       "0                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "1                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "2                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "3                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "4                       1  criminal-mischief-mtr-veh     public-disorder   \n",
       "\n",
       "   FIRST_OCCURRENCE_DATE  LAST_OCCURRENCE_DATE          REPORTED_DATE  ...  \\\n",
       "0   8/2/2020 10:43:00 PM                   NaN   8/2/2020 10:43:00 PM  ...   \n",
       "1   4/20/2019 7:30:00 AM  4/20/2019 8:45:00 AM   4/20/2019 6:30:00 PM  ...   \n",
       "2  2/25/2020 11:30:00 PM  2/26/2020 6:45:00 AM   2/26/2020 7:30:00 AM  ...   \n",
       "3   11/1/2021 6:20:00 AM  11/1/2021 6:30:00 AM  11/1/2021 10:15:00 AM  ...   \n",
       "4   5/9/2020 12:00:00 PM                   NaN  5/11/2020 12:05:00 PM  ...   \n",
       "\n",
       "      GEO_LON    GEO_LAT  DISTRICT_ID  PRECINCT_ID  NEIGHBORHOOD_ID IS_CRIME  \\\n",
       "0 -105.024597  39.689751            4          422        ruby-hill        1   \n",
       "1 -104.987348  39.714316            3          311            speer        1   \n",
       "2 -104.988098  39.764528            6          612      five-points        1   \n",
       "3 -105.004665  39.739669            1          123     lincoln-park        1   \n",
       "4 -104.830661  39.795281            5          521        montbello        1   \n",
       "\n",
       "   IS_TRAFFIC VICTIM_COUNT             x             y  \n",
       "0           0            1  3.133789e+06  1.676471e+06  \n",
       "1           0            1  3.144221e+06  1.685476e+06  \n",
       "2           0            1  3.143907e+06  1.703765e+06  \n",
       "3           0            1  3.139299e+06  1.694684e+06  \n",
       "4           0            1  3.188083e+06  1.715255e+06  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 394736 records!\n"
     ]
    }
   ],
   "source": [
    "# Find all crime data CSV files matching the naming pattern\n",
    "csv_files = glob.glob(\"data/crime_split_*.csv\")\n",
    "\n",
    "# Read in all of the files and create Pandas dataframes from them\n",
    "split_dfs = [pd.read_csv(f) for f in csv_files]\n",
    "\n",
    "# Concatenate all the dataframes into a single one\n",
    "df = pd.concat(split_dfs, ignore_index=True)\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "original_dataframe_shape = df.shape\n",
    "print(f'Loaded {original_dataframe_shape[0]} records!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Analysis\n",
    "The next thing to do is determine which columns will be useful for predictions and which columns need to be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime Dataset Columns:\n",
      " - OBJECTID\n",
      " - INCIDENT_ID\n",
      " - OFFENSE_ID\n",
      " - OFFENSE_CODE\n",
      " - OFFENSE_CODE_EXTENSION\n",
      " - OFFENSE_TYPE_ID\n",
      " - OFFENSE_CATEGORY_ID\n",
      " - FIRST_OCCURRENCE_DATE\n",
      " - LAST_OCCURRENCE_DATE\n",
      " - REPORTED_DATE\n",
      " - INCIDENT_ADDRESS\n",
      " - GEO_X\n",
      " - GEO_Y\n",
      " - GEO_LON\n",
      " - GEO_LAT\n",
      " - DISTRICT_ID\n",
      " - PRECINCT_ID\n",
      " - NEIGHBORHOOD_ID\n",
      " - IS_CRIME\n",
      " - IS_TRAFFIC\n",
      " - VICTIM_COUNT\n",
      " - x\n",
      " - y\n"
     ]
    }
   ],
   "source": [
    "print(\"Crime Dataset Columns:\")\n",
    "for column in df.columns:\n",
    "    print(f\" - {column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Decisions\n",
    "| Column ID                 | Decision  | Explanation                                                                                        |\n",
    "|---------------------------|-----------|----------------------------------------------------------------------------------------------------|\n",
    "| `OBJECTID`                | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `INCIDENT_ID`             | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_ID`              | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_CODE`            | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_CODE_EXTENSION`  | Discarded | Related to the database how how the data is stored, identified, or queried. No predictive value.   |\n",
    "| `OFFENSE_TYPE_ID`         | Kept      | This is part of the output (y-values). We will keep this column and it will be the subject of prediction by the classification model. |\n",
    "| `OFFENSE_CATEGORY_ID`     | Discarded | This is part of the output (y-values). This will be discarded in  |\n",
    "| `FIRST_OCCURRENCE_DATE`   | Kept      | Timestamp of the event, this will be kept and used for predictions made based on the time of day. |\n",
    "| `LAST_OCCURRENCE_DATE`    | Discarded | Undefined for many rows. We will discard this timestamp and rely on `FIRST_OCCURRENCE_DATE` instead.                              |\n",
    "| `REPORTED_DATE`           | Discarded | This is part of the output (y-values). Report time delta from occurrence varies incident to incident. No predictive value.                             |\n",
    "| `INCIDENT_ADDRESS`        | Discarded | Although address is useful, this column is not standardized with entries like \"2400 block\" rather than exact addresses in some cases. |\n",
    "| `GEO_X`                   | Discarded | Related to the mapping platform the data was posted on. No predictive value.                    |\n",
    "| `GEO_Y`                   | Discarded | Related to the mapping platform the data was posted on. No predictive value.                    |\n",
    "| `GEO_LON`                 | Kept      | Location of the crime, this will be kept and used to make predictions based on location. |\n",
    "| `GEO_LAT`                 | Kept      | Location of the crime, this will be kept and used to make predictions based on location. |\n",
    "| `DISTRICT_ID`             | Discarded | This is part of the output (y-values) and we have no way of querying. No predictive value.                    |\n",
    "| `PRECINCT_ID`             | Discarded | This is part of the output (y-values) and we have no way of querying. No predictive value.                             |\n",
    "| `NEIGHBORHOOD_ID`         | Discarded | Although neighborhood is useful, as some are \"rougher\" than others, we don't have a standard way of querying.                             |\n",
    "| `IS_CRIME`                | Discarded | This is part of the output (y-values). No predictive value.                             |\n",
    "| `IS_TRAFFIC`              | Discarded | This is part of the output (y-values). No predictive value.                             |\n",
    "| `VICTIM_COUNT`            | Discarded | This is part of the output (y-values). No predictive value.                             |\n",
    "| `x`                       | Discarded | Related to the mapping platform the data was posted on. No predictive value.                     |\n",
    "| `y`                       | Discarded | Related to the mapping platform the data was posted on. No predictive value.                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>FIRST_OCCURRENCE_DATE</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196113</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>6/27/2022 12:01:00 AM</td>\n",
       "      <td>-104.893000</td>\n",
       "      <td>39.628501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161959</th>\n",
       "      <td>robbery-street</td>\n",
       "      <td>7/13/2022 2:00:00 AM</td>\n",
       "      <td>-104.975015</td>\n",
       "      <td>39.738355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53372</th>\n",
       "      <td>theft-items-from-vehicle</td>\n",
       "      <td>4/20/2021 1:00:00 PM</td>\n",
       "      <td>-104.914276</td>\n",
       "      <td>39.731238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110466</th>\n",
       "      <td>sex-off-fail-to-register</td>\n",
       "      <td>4/15/2022 8:00:00 AM</td>\n",
       "      <td>-104.992313</td>\n",
       "      <td>39.737154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5928</th>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>9/25/2022 10:00:00 PM</td>\n",
       "      <td>-105.013461</td>\n",
       "      <td>39.756894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161133</th>\n",
       "      <td>robbery-street</td>\n",
       "      <td>6/14/2019 12:00:00 AM</td>\n",
       "      <td>-104.848629</td>\n",
       "      <td>39.781065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>9/8/2020 9:00:00 AM</td>\n",
       "      <td>-105.027847</td>\n",
       "      <td>39.679431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119213</th>\n",
       "      <td>weapon-carrying-concealed</td>\n",
       "      <td>12/19/2021 12:58:00 AM</td>\n",
       "      <td>-104.949351</td>\n",
       "      <td>39.778771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381992</th>\n",
       "      <td>theft-items-from-vehicle</td>\n",
       "      <td>1/5/2024 1:05:00 AM</td>\n",
       "      <td>-104.970282</td>\n",
       "      <td>39.719495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249083</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>2/8/2024 4:30:00 PM</td>\n",
       "      <td>-105.025362</td>\n",
       "      <td>39.704777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195365</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>1/10/2021 12:00:00 AM</td>\n",
       "      <td>-105.035070</td>\n",
       "      <td>39.631609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69108</th>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>5/24/2021 2:48:00 PM</td>\n",
       "      <td>-104.998269</td>\n",
       "      <td>39.721188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250372</th>\n",
       "      <td>drug-opium-or-deriv-sell</td>\n",
       "      <td>2/21/2024 1:56:00 PM</td>\n",
       "      <td>-105.002539</td>\n",
       "      <td>39.738614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209738</th>\n",
       "      <td>burglary-residence-by-force</td>\n",
       "      <td>7/26/2024 7:00:00 AM</td>\n",
       "      <td>-104.898977</td>\n",
       "      <td>39.734093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320920</th>\n",
       "      <td>theft-other</td>\n",
       "      <td>7/28/2019 9:30:00 AM</td>\n",
       "      <td>-104.952574</td>\n",
       "      <td>39.733791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216333</th>\n",
       "      <td>violation-of-restraining-order</td>\n",
       "      <td>5/20/2024 12:58:00 AM</td>\n",
       "      <td>-105.038057</td>\n",
       "      <td>39.728091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162491</th>\n",
       "      <td>robbery-residence</td>\n",
       "      <td>5/22/2021 11:00:00 PM</td>\n",
       "      <td>-104.824541</td>\n",
       "      <td>39.789176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49921</th>\n",
       "      <td>burglary-residence-by-force</td>\n",
       "      <td>6/30/2023 4:00:00 PM</td>\n",
       "      <td>-104.942614</td>\n",
       "      <td>39.736062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357946</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>1/3/2022 7:00:00 PM</td>\n",
       "      <td>-104.773894</td>\n",
       "      <td>39.792485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305683</th>\n",
       "      <td>violation-of-court-order</td>\n",
       "      <td>11/1/2022 7:21:00 AM</td>\n",
       "      <td>-105.035373</td>\n",
       "      <td>39.708287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       OFFENSE_TYPE_ID   FIRST_OCCURRENCE_DATE     GEO_LON  \\\n",
       "196113          theft-of-motor-vehicle   6/27/2022 12:01:00 AM -104.893000   \n",
       "161959                  robbery-street    7/13/2022 2:00:00 AM -104.975015   \n",
       "53372         theft-items-from-vehicle    4/20/2021 1:00:00 PM -104.914276   \n",
       "110466        sex-off-fail-to-register    4/15/2022 8:00:00 AM -104.992313   \n",
       "5928         criminal-mischief-mtr-veh   9/25/2022 10:00:00 PM -105.013461   \n",
       "161133                  robbery-street   6/14/2019 12:00:00 AM -104.848629   \n",
       "1288         criminal-mischief-mtr-veh     9/8/2020 9:00:00 AM -105.027847   \n",
       "119213       weapon-carrying-concealed  12/19/2021 12:58:00 AM -104.949351   \n",
       "381992        theft-items-from-vehicle     1/5/2024 1:05:00 AM -104.970282   \n",
       "249083          theft-of-motor-vehicle     2/8/2024 4:30:00 PM -105.025362   \n",
       "195365          theft-of-motor-vehicle   1/10/2021 12:00:00 AM -105.035070   \n",
       "69108        criminal-mischief-mtr-veh    5/24/2021 2:48:00 PM -104.998269   \n",
       "250372        drug-opium-or-deriv-sell    2/21/2024 1:56:00 PM -105.002539   \n",
       "209738     burglary-residence-by-force    7/26/2024 7:00:00 AM -104.898977   \n",
       "320920                     theft-other    7/28/2019 9:30:00 AM -104.952574   \n",
       "216333  violation-of-restraining-order   5/20/2024 12:58:00 AM -105.038057   \n",
       "162491               robbery-residence   5/22/2021 11:00:00 PM -104.824541   \n",
       "49921      burglary-residence-by-force    6/30/2023 4:00:00 PM -104.942614   \n",
       "357946          theft-of-motor-vehicle     1/3/2022 7:00:00 PM -104.773894   \n",
       "305683        violation-of-court-order    11/1/2022 7:21:00 AM -105.035373   \n",
       "\n",
       "          GEO_LAT  \n",
       "196113  39.628501  \n",
       "161959  39.738355  \n",
       "53372   39.731238  \n",
       "110466  39.737154  \n",
       "5928    39.756894  \n",
       "161133  39.781065  \n",
       "1288    39.679431  \n",
       "119213  39.778771  \n",
       "381992  39.719495  \n",
       "249083  39.704777  \n",
       "195365  39.631609  \n",
       "69108   39.721188  \n",
       "250372  39.738614  \n",
       "209738  39.734093  \n",
       "320920  39.733791  \n",
       "216333  39.728091  \n",
       "162491  39.789176  \n",
       "49921   39.736062  \n",
       "357946  39.792485  \n",
       "305683  39.708287  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep only the columns that we want\n",
    "df = df[['OFFENSE_TYPE_ID','FIRST_OCCURRENCE_DATE','GEO_LON','GEO_LAT']]\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Binning\n",
    "In this analysis, time binning is used to capture the cyclical and seasonal patterns inherent in criminal behavior. Crime often follows temporal trends—certain types of incidents may be more likely to occur at specific times of day, days of the week, or during particular seasons. For example, incidents related to nightlife might peak during late evening hours, while other crimes may correlate with daily commuter traffic or specific days like weekends. By extracting temporal features like `YEAR`, `DAY_OF_YEAR`, `DAY_OF_WEEK`, and a continuous `TIME` (floating-point hour), we enable the model to identify these patterns and trends. This granular binning enhances the predictive power of the model, allowing it to detect not only broad time-based patterns but also more subtle nuances in how crime evolves throughout the day, week, and year.\n",
    "\n",
    "#### Temporal Features Breakdown\n",
    "* `YEAR`: Provides a clear yearly context, which can be crucial for identifying long-term trends or annual shifts in patterns.\n",
    "* `TIME` (floating point): Offers a precise measure of the time of day, allowing models to pick up on subtle temporal shifts within a 24-hour cycle.\n",
    "* `DAY_OF_YEAR`: Captures the day within the year, useful for identifying seasonal patterns or trends that recur annually.\n",
    "* `DAY_OF_WEEK`: Encodes weekly cycles, helping the model detect patterns associated with specific weekdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>GEO_LON</th>\n",
       "      <th>GEO_LAT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175573</th>\n",
       "      <td>burglary-residence-no-force</td>\n",
       "      <td>-105.000288</td>\n",
       "      <td>39.756199</td>\n",
       "      <td>2019</td>\n",
       "      <td>13</td>\n",
       "      <td>276</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260719</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>-104.927856</td>\n",
       "      <td>39.768489</td>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323915</th>\n",
       "      <td>theft-bicycle</td>\n",
       "      <td>-104.974631</td>\n",
       "      <td>39.760658</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200078</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>-104.917871</td>\n",
       "      <td>39.675902</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79317</th>\n",
       "      <td>criminal-mischief-other</td>\n",
       "      <td>-105.002030</td>\n",
       "      <td>39.745698</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    OFFENSE_TYPE_ID     GEO_LON    GEO_LAT  YEAR  HOUR  \\\n",
       "175573  burglary-residence-no-force -105.000288  39.756199  2019    13   \n",
       "260719       theft-of-motor-vehicle -104.927856  39.768489  2022    18   \n",
       "323915                theft-bicycle -104.974631  39.760658  2021     3   \n",
       "200078       theft-of-motor-vehicle -104.917871  39.675902  2020    12   \n",
       "79317       criminal-mischief-other -105.002030  39.745698  2021    12   \n",
       "\n",
       "        DAY_OF_YEAR  DAY_OF_WEEK  \n",
       "175573          276            3  \n",
       "260719          125            3  \n",
       "323915          252            3  \n",
       "200078          281            2  \n",
       "79317           127            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert FIRST_OCCURRENCE_DATE to Pandas date time format\n",
    "df['FIRST_OCCURRENCE_DATE'] = pd.to_datetime(df['FIRST_OCCURRENCE_DATE'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# Extract date and time components\n",
    "df['YEAR'] = df['FIRST_OCCURRENCE_DATE'].dt.year\n",
    "# df['MONTH'] = df['FIRST_OCCURRENCE_DATE'].dt.month -- Removed in favor of DAY_OF_YEAR\n",
    "# df['DAY_OF_MONTH'] = df['FIRST_OCCURRENCE_DATE'].dt.day -- Removed in favor of DAY_OF_YEAR\n",
    "# df['TIME'] = (\n",
    "#     df['FIRST_OCCURRENCE_DATE'].dt.hour + \n",
    "#     df['FIRST_OCCURRENCE_DATE'].dt.minute / 60 + \n",
    "#     df['FIRST_OCCURRENCE_DATE'].dt.second / 3600\n",
    "# ) -- No longer doing floating point hour\n",
    "df['HOUR'] = df['FIRST_OCCURRENCE_DATE'].dt.hour\n",
    "df['DAY_OF_YEAR'] = df['FIRST_OCCURRENCE_DATE'].dt.dayofyear\n",
    "df['DAY_OF_WEEK'] = df['FIRST_OCCURRENCE_DATE'].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Finally, dropping the FIRST_OCCURRENCE_DATE column\n",
    "df.drop(columns=['FIRST_OCCURRENCE_DATE'], inplace=True)\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Slicing & Binning \n",
    "In this step, we convert latitude and longitude into a 15-meter by 15-meter grid system using a projected coordinate system (UTM). This method ensures that each crime location is assigned to a unique, precise grid cell, facilitating accurate spatial analysis.\n",
    "\n",
    "See <https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system>\n",
    "\n",
    "#### Why This is Better Than Using Raw Latitude and Longitude\n",
    "\n",
    "Using UTM coordinates overcomes the limitations of raw latitude and longitude, which vary in distance depending on location. UTM coordinates provide uniform distance measurements in meters, improving precision and making it easier to define consistent grid cells. This approach also simplifies spatial analysis by grouping data into fixed-size cells, making patterns like crime hotspots easier to identify and computationally more efficient to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size before removal: 394736 items\n",
      "Dataframe size after removal: 394475 items\n",
      "--> 261 items removed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_TYPE_ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>X_BLOCK</th>\n",
       "      <th>Y_BLOCK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198778</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>2022</td>\n",
       "      <td>19</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>33775</td>\n",
       "      <td>293390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89757</th>\n",
       "      <td>theft-items-from-vehicle</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>33822</td>\n",
       "      <td>292787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47325</th>\n",
       "      <td>criminal-mischief-mtr-veh</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>4</td>\n",
       "      <td>33926</td>\n",
       "      <td>293300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261069</th>\n",
       "      <td>theft-of-motor-vehicle</td>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>33431</td>\n",
       "      <td>293297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217244</th>\n",
       "      <td>indecent-exposure</td>\n",
       "      <td>2024</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>4</td>\n",
       "      <td>33369</td>\n",
       "      <td>292937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  OFFENSE_TYPE_ID  YEAR  HOUR  DAY_OF_YEAR  DAY_OF_WEEK  \\\n",
       "198778     theft-of-motor-vehicle  2022    19           96            2   \n",
       "89757    theft-items-from-vehicle  2022    16           79            6   \n",
       "47325   criminal-mischief-mtr-veh  2023     3          174            4   \n",
       "261069     theft-of-motor-vehicle  2021    17          180            1   \n",
       "217244          indecent-exposure  2024     0          131            4   \n",
       "\n",
       "        X_BLOCK  Y_BLOCK  \n",
       "198778    33775   293390  \n",
       "89757     33822   292787  \n",
       "47325     33926   293300  \n",
       "261069    33431   293297  \n",
       "217244    33369   292937  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GRID_SIZE = 15 # 15m x 15m grid cells\n",
    "\n",
    "# Initialize UTM projection (assuming UTM Zone 13N for Denver)\n",
    "#   https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system\n",
    "#   https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system#/media/File:Universal_Transverse_Mercator_zones.svg\n",
    "utm_proj = pyproj.Proj(proj=\"utm\", zone=13, datum=\"WGS84\")\n",
    "\n",
    "def get_grid_block(lat, lon):\n",
    "    try:\n",
    "        # Convert latitude and longitude to UTM coordinates (X, Y)\n",
    "        x, y = utm_proj(lon, lat)  # Correct order: lon, lat\n",
    "        \n",
    "        # Calculate the X and Y blocks\n",
    "        x_block = int(x // GRID_SIZE)\n",
    "        y_block = int(y // GRID_SIZE)\n",
    "        \n",
    "        return x_block, y_block\n",
    "    except:\n",
    "        # If there is an issue parsing, return -1\n",
    "        return -1, -1\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df[['X_BLOCK', 'Y_BLOCK']] = df.apply(lambda row: get_grid_block(row['GEO_LAT'], row['GEO_LON']), axis=1, result_type='expand')\n",
    "\n",
    "# Drop rows where X_BLOCK or Y_BLOCK is -1\n",
    "df = df[(df['X_BLOCK'] != -1) & (df['Y_BLOCK'] != -1)]\n",
    "\n",
    "# Note change in size\n",
    "post_null_geo_block_removal_dataframe_shape = df.shape\n",
    "print(f'Dataframe size before removal: {original_dataframe_shape[0]} items')\n",
    "print(f'Dataframe size after removal: {post_null_geo_block_removal_dataframe_shape[0]} items')\n",
    "print(f'--> {original_dataframe_shape[0] - post_null_geo_block_removal_dataframe_shape[0]} items removed!')\n",
    "\n",
    "# Finally, dropping the GEO_LAT and GEO_LON columns since we have replaced them with X_BLOCK and Y_BLOCK\n",
    "df.drop(columns=['GEO_LAT'], inplace=True)\n",
    "df.drop(columns=['GEO_LON'], inplace=True)\n",
    "\n",
    "# Displaying a random sample of the data to confirm what it looks like\n",
    "display(df.sample(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are processing the geographical data to assign each crime incident to a specific grid cell based on its latitude and longitude. We achieve this by converting the coordinates to UTM projection, which provides more accurate distance-based calculations than traditional latitude and longitude. For each point, we calculate the corresponding grid cell by dividing the UTM coordinates by the grid size (15 meters) and then storing the results as `X_BLOCK` and `Y_BLOCK`.\n",
    "\n",
    "However, if any coordinates cannot be processed correctly (due to projection issues or invalid data), we assign -1 as a placeholder. After applying this transformation, we remove any rows where either the `X_BLOCK` or `Y_BLOCK` is -1, indicating invalid grid assignments. The sizes of the DataFrame before and after this removal are printed to highlight the impact of cleaning the data. This step ensures that only valid data points are included for further analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Location Outliers\n",
    "When exporting the data as a CSV file, it can be observed that some of the rows have really low or high X-block values. These are likely location mis-inputs.\n",
    "\n",
    "We can drop these rows by calculating the interquartile range range for the `X_BLOCK` and `Y_BLOCK` columns and dropping the rows that are outliers.\n",
    "\n",
    "What I have done below is not the interquartile range. I only want to drop extreme outliers, so I dropped the values that fall outside the middle 98% of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before location outlier removal: 394475 records.\n",
      "Size after location outlier removal: 394434 records.\n",
      "--> 41 records removed!\n"
     ]
    }
   ],
   "source": [
    "df_shape_before_location_outlier_drop = df.shape\n",
    "\n",
    "Q1 = df['X_BLOCK'].quantile(0.01)\n",
    "Q3 = df['X_BLOCK'].quantile(0.99)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df = df.loc[(df['X_BLOCK'] >= lower_bound) & (df['X_BLOCK'] <= upper_bound)]\n",
    "\n",
    "# Calculate and display rows removed\n",
    "df_shape_after_location_outlier_drop = df.shape\n",
    "print(f'Size before location outlier removal: {df_shape_before_location_outlier_drop[0]} records.')\n",
    "print(f'Size after location outlier removal: {df_shape_after_location_outlier_drop[0]} records.')\n",
    "print(f'--> {df_shape_before_location_outlier_drop[0] - df_shape_after_location_outlier_drop[0]} records removed!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in OpenStreetMap Features\n",
    "In this section, we aim to enrich our dataset with spatial features from OpenStreetMap (OSM). By querying OSM data for geographic features based on the centroids of the X and Y grid blocks (calculated from latitude and longitude), we can incorporate valuable context such as the proximity to roads, points of interest, or land use types. This spatial data enhances our analysis by providing a richer understanding of the environment in which the crimes occur, potentially improving predictive modeling. By leveraging OpenStreetMap data, we can gather additional information about the geographical characteristics of each grid cell, allowing for more nuanced predictions based on spatial context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "# Import osmium to parse the OSM files\n",
    "import osmium\n",
    "\n",
    "# Re-define the UTM projections from earlier\n",
    "utm_proj = pyproj.Proj(proj=\"utm\", zone=13, datum=\"WGS84\")\n",
    "latlon_proj = pyproj.Proj(proj=\"latlong\", datum=\"WGS84\")\n",
    "\n",
    "# Define tranformers\n",
    "latlon_to_utm_transformer = pyproj.Transformer.from_proj(latlon_proj, utm_proj)\n",
    "utm_to_latlon_transformer = pyproj.Transformer.from_proj(utm_proj, latlon_proj)\n",
    "\n",
    "'''\n",
    "    Generate a Grid of Map Blocks/Cells from predefined corners.\n",
    "'''\n",
    "def gen_blocks_from_coordinates(southwest_corner, northeast_corner, database_path):\n",
    "    # Bounding corners\n",
    "    def dec_coordinates(str_coordinates):\n",
    "        parts = str_coordinates.split(\",\")\n",
    "        \n",
    "        # Extract latitude from the first part and longitude from the second part\n",
    "        lat = float(re.findall(r\"\\d+\\.\\d+\", parts[0])[0])\n",
    "        lon = float(re.findall(r\"\\d+\\.\\d+\", parts[1])[0])\n",
    "        \n",
    "        # Adjust sign based on N/S and E/W indicators\n",
    "        if \"S\" in parts[0]:\n",
    "            lat = -lat\n",
    "        if \"W\" in parts[1]:\n",
    "            lon = -lon\n",
    "            \n",
    "        return lon, lat  # Return (longitude, latitude)\n",
    "\n",
    "    southwest_lon, southwest_lat = dec_coordinates(southwest_corner)\n",
    "    northeast_lon, northeast_lat = dec_coordinates(northeast_corner)\n",
    "\n",
    "    # Define block size in meters (15 meters as mentioned)\n",
    "    block_size = 15\n",
    "\n",
    "    # Create a transformer for converting lat/lon to UTM\n",
    "    latlon_to_utm_transformer = pyproj.Transformer.from_proj(latlon_proj, utm_proj)\n",
    "\n",
    "    # Convert southwest and northeast corners to UTM\n",
    "    southwest_x, southwest_y = latlon_to_utm_transformer.transform(southwest_lon, southwest_lat)\n",
    "    northeast_x, northeast_y = latlon_to_utm_transformer.transform(northeast_lon, northeast_lat)\n",
    "\n",
    "    # Calculate the area width and height in meters\n",
    "    area_width = northeast_x - southwest_x\n",
    "    area_height = northeast_y - southwest_y\n",
    "\n",
    "    # Calculate the number of blocks in the area\n",
    "    num_x_blocks = int(area_width // block_size)\n",
    "    num_y_blocks = int(area_height // block_size)\n",
    "\n",
    "    # Create SQLite database and table\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store the map cells\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS blocks (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            x_block INTEGER,\n",
    "            y_block INTEGER,\n",
    "            cent_lat REAL,\n",
    "            cent_lon REAL\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Function to calculate the centroid of a block (in UTM)\n",
    "    def get_centroid(x_block, y_block, grid_size=15):\n",
    "        # Create a transformer for converting UTM to lat/lon\n",
    "        utm_to_latlon_transformer = pyproj.Transformer.from_proj(utm_proj, latlon_proj)\n",
    "        \n",
    "        # Get the bottom-left corner coordinates in UTM\n",
    "        x_origin, y_origin = x_block * grid_size, y_block * grid_size\n",
    "        \n",
    "        # Calculate the centroid by moving half the grid size in both directions\n",
    "        x_centroid = x_origin + grid_size / 2\n",
    "        y_centroid = y_origin + grid_size / 2\n",
    "        \n",
    "        # Convert UTM coordinates to latitude and longitude\n",
    "        lon, lat = utm_to_latlon_transformer.transform(x_centroid, y_centroid)\n",
    "        \n",
    "        return lat, lon\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    total_blocks = num_x_blocks * num_y_blocks\n",
    "\n",
    "    # Set the batch size\n",
    "    batch_size = 100000\n",
    "    batch_data = []\n",
    "\n",
    "    # Init the progress bar\n",
    "    progress_bar = tqdm(total=total_blocks, desc=\"Identifying Block Centroids\", position=0, ncols=120)\n",
    "\n",
    "    # Loop through each block and calculate the centroid\n",
    "    for y_block in range(num_y_blocks):\n",
    "        for x_block in range(num_x_blocks):\n",
    "            # Calculate the centroid for the current block\n",
    "            lat, lon = get_centroid(x_block, y_block, block_size)\n",
    "            \n",
    "            # Append data to batch\n",
    "            batch_data.append((x_block, y_block, lat, lon))\n",
    "            \n",
    "            # If batch size is reached, execute the batch insert\n",
    "            if len(batch_data) >= batch_size:\n",
    "                cursor.executemany('''\n",
    "                    INSERT INTO blocks (x_block, y_block, cent_lat, cent_lon)\n",
    "                    VALUES (?, ?, ?, ?)\n",
    "                ''', batch_data)\n",
    "                \n",
    "                # Manually update the progress bar after each block\n",
    "                progress_bar.update(len(batch_data))\n",
    "                \n",
    "                conn.commit()  # Commit after each batch\n",
    "                batch_data = []  # Clear the batch data\n",
    "\n",
    "    # Insert any remaining data after the loop\n",
    "    if batch_data:\n",
    "        cursor.executemany('''\n",
    "            INSERT INTO blocks (x_block, y_block, cent_lat, cent_lon)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        ''', batch_data)\n",
    "\n",
    "        progress_bar.update(len(batch_data))\n",
    "\n",
    "        conn.commit()  # Final commit for remaining data\n",
    "\n",
    "    # Close the progress bar once finished\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Close the SQLite connection\n",
    "    conn.close()\n",
    "\n",
    "'''\n",
    "    Generate a map based on the boundaries of the available crime location data, plus a margin\n",
    "'''\n",
    "def gen_map_from_crime_location_data_with_margin(crime_df, margin, database_path):\n",
    "    # Get the limits of the locations saved within the data frame\n",
    "    x_max = crime_df['X_BLOCK'].max()\n",
    "    x_min = crime_df['X_BLOCK'].min()\n",
    "    y_max = crime_df['Y_BLOCK'].max()\n",
    "    y_min = crime_df['Y_BLOCK'].min()\n",
    "\n",
    "    # Calculate the limits with the \n",
    "    x_max_margin = x_max + margin\n",
    "    x_min_margin = x_min - margin\n",
    "    y_max_margin = y_max + margin\n",
    "    y_min_margin = y_min - margin\n",
    "\n",
    "    # Print the map size\n",
    "    print(f\"Map Size Before Margin (in blocks): Upper Left Corner: ({x_min}, {y_max}), Lower Right Corner: ({x_max}, {y_min})\")\n",
    "    print(f\"Map Size After Margin (in blocks): Upper Left Corner: ({x_min_margin}, {y_max_margin}), Lower Right Corner: ({x_max_margin}, {y_min_margin})\")\n",
    "\n",
    "    # Function to get the edges of the box in lon/lat\n",
    "    def block_to_latlon(x, y):\n",
    "        # Project from UTM to latlon\n",
    "        transformer = pyproj.Transformer.from_crs(f\"epsg:32613\", \"epsg:4326\", always_xy=True)\n",
    "        return transformer.transform(x * GRID_SIZE, y * GRID_SIZE)\n",
    "\n",
    "    min_longitude, min_latitude = block_to_latlon(x_min_margin, y_min_margin)\n",
    "    max_longitude, max_latitude = block_to_latlon(x_max_margin, y_max_margin)\n",
    "    print(f\"    (lon, lat): ({min_longitude},{min_latitude}) ({max_longitude},{max_latitude})\")\n",
    "\n",
    "    # Loop through the each possible block in the map, including the margins\n",
    "    total_blocks = (x_max_margin - x_min_margin) * (y_max_margin - y_min_margin)\n",
    "    print(f'--> Total map grid cells: {total_blocks}')\n",
    "    \n",
    "    # Create SQLite database and table\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create a table to store the map cells\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS blocks (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            x INTEGER,\n",
    "            y INTEGER,\n",
    "            c_lat REAL,\n",
    "            c_lon REAL,\n",
    "            tags TEXT\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Set the batch size\n",
    "    batch_size = 1\n",
    "    batch_data = []\n",
    "    \n",
    "    # Init the progress bar\n",
    "    progress_bar = tqdm(total=total_blocks, desc=\"Building Map\", position=0, ncols=120)\n",
    "\n",
    "    for x in range(x_min_margin, x_max_margin + 1):\n",
    "        for y in range(y_min_margin, y_max_margin + 1):\n",
    "            # Get important latitudes and longitudes\n",
    "            center_lon, center_lat = block_to_latlon(x + (GRID_SIZE / 2), y - (GRID_SIZE / 2))\n",
    "\n",
    "            tags = []\n",
    "            \n",
    "            for obj in osmium.FileProcessor('../denver_filtered.osm.pbf', osmium.osm.NODE):\n",
    "                if obj.tags:\n",
    "                    tags += obj,tags\n",
    "                try:\n",
    "                    if osmium.geom.haversine_distance(osmium.osm.Location(center_lon, center_lat), obj.location) < (GRID_SIZE * 1.5):\n",
    "                        continue\n",
    "                except:\n",
    "                    print(obj)\n",
    "            \n",
    "            print(tags)\n",
    "            \n",
    "            batch_data.append((\n",
    "                x,          #\n",
    "                y,          #\n",
    "                center_lon, #\n",
    "                center_lat, #\n",
    "                str(tags)        #\n",
    "            ))\n",
    "\n",
    "            # If batch size is reached, execute the batch insert\n",
    "            if len(batch_data) >= batch_size:\n",
    "                cursor.executemany('''\n",
    "                    INSERT INTO blocks (x, y, c_lat, c_lon, tags)\n",
    "                    VALUES (?, ?, ?, ?, ?)\n",
    "                ''', batch_data)\n",
    "                \n",
    "                # Manually update the progress bar after each block\n",
    "                progress_bar.update(len(batch_data))\n",
    "                \n",
    "                conn.commit()  # Commit after each batch\n",
    "                batch_data = []  # Clear the batch data\n",
    "            \n",
    "    # Insert any remaining data after the loop\n",
    "    if batch_data:\n",
    "        cursor.executemany('''\n",
    "            INSERT INTO blocks (x, y, c_lat, c_lon, tags)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        ''', batch_data)\n",
    "\n",
    "        progress_bar.update(len(batch_data))\n",
    "\n",
    "        conn.commit()  # Final commit for remaining data\n",
    "\n",
    "    # Close the SQLite connection\n",
    "    conn.close()    \n",
    "    \n",
    "    # Close the progress bar once finished\n",
    "    progress_bar.close()\n",
    "\n",
    "# Old method was just a fixed area\n",
    "southwest_corner = \"39.53440° N, 105.24364° W\"\n",
    "northeast_corner = \"40.03841° N, 104.58877° W\"\n",
    "database_path = 'map_grid.db'\n",
    "#gen_blocks_from_coordinates(southwest_corner, northeast_corner, database_path)\n",
    "\n",
    "# gen_map_from_crime_location_data_with_margin(df, 400, 'map.db')\n",
    "# -- Skipping... see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "12676781 * 17 / 60 / 60 / 24 / 365 = 6.8336275051 \\text{ years to process the OSM data}\n",
    "$$\n",
    "For now, I will set aside the extraction of OpenStreetMap (OSM) features due to the excessive processing time — approximately 6.83 years — required to handle the data with my current approach. The complexity of querying and filtering OSM data, even with optimization attempts, has proven to be a significant bottleneck. As a result, I will proceed with exploratory data analysis (EDA) using the existing crime dataset without incorporating OSM features. This will allow me to focus on other aspects of the analysis and revisit the OSM integration if a more efficient method becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the initial dataframe\n",
    "original_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Type Model (Gradient Boosting Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    47402\n",
      "148    32539\n",
      "35     22177\n",
      "154    20602\n",
      "153    18918\n",
      "       ...  \n",
      "92         2\n",
      "177        2\n",
      "68         2\n",
      "90         2\n",
      "86         2\n",
      "Name: count, Length: 171, dtype: int64\n",
      "Test Class Distribution:\n",
      " OFFENSE_TYPE_ID\n",
      "150    11851\n",
      "148     8135\n",
      "35      5544\n",
      "154     5151\n",
      "153     4730\n",
      "       ...  \n",
      "113        1\n",
      "86         1\n",
      "123        1\n",
      "109        1\n",
      "94         1\n",
      "Name: count, Length: 164, dtype: int64\n",
      "Accuracy: 0.13549932814441093\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        11\n",
      "           1       0.07      0.10      0.08        61\n",
      "           2       0.02      0.01      0.01       187\n",
      "           3       0.06      0.01      0.01      1442\n",
      "           4       0.01      0.00      0.00       656\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00        26\n",
      "           9       0.00      0.00      0.00        64\n",
      "          10       0.00      0.00      0.00         4\n",
      "          11       0.00      0.00      0.00        30\n",
      "          12       0.00      0.00      0.00        47\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.02      0.00      0.00       981\n",
      "          15       0.02      0.02      0.02       149\n",
      "          16       0.12      0.01      0.02      2916\n",
      "          18       0.02      0.03      0.02        39\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00        23\n",
      "          21       0.03      0.03      0.03        65\n",
      "          22       0.00      0.01      0.01       127\n",
      "          23       0.00      0.00      0.00        29\n",
      "          24       0.23      0.07      0.11      1845\n",
      "          25       0.02      0.01      0.01       505\n",
      "          26       0.02      0.03      0.03        88\n",
      "          27       0.00      0.00      0.00        76\n",
      "          28       0.03      0.00      0.01      1240\n",
      "          29       0.05      0.00      0.01      1699\n",
      "          30       0.00      0.00      0.00        25\n",
      "          31       0.00      0.00      0.00        28\n",
      "          32       0.02      0.01      0.01        79\n",
      "          33       0.00      0.00      0.00         9\n",
      "          34       0.08      0.05      0.06       497\n",
      "          35       0.11      0.02      0.03      5544\n",
      "          36       0.05      0.00      0.01      3310\n",
      "          37       0.22      0.10      0.13      2918\n",
      "          38       0.10      0.13      0.11        86\n",
      "          39       0.00      0.00      0.00         9\n",
      "          40       0.02      0.01      0.01       726\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.03      0.02      0.02       166\n",
      "          45       0.16      0.15      0.15       202\n",
      "          46       0.00      0.00      0.00         4\n",
      "          47       0.00      0.00      0.00        18\n",
      "          48       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         9\n",
      "          50       0.00      0.00      0.00        10\n",
      "          51       0.00      0.00      0.00       140\n",
      "          52       0.03      0.06      0.04        54\n",
      "          53       0.00      0.00      0.00        43\n",
      "          54       0.07      0.18      0.10        11\n",
      "          55       0.00      0.00      0.00        37\n",
      "          56       0.02      0.04      0.02        28\n",
      "          57       0.04      0.02      0.03       521\n",
      "          58       0.01      0.01      0.01       194\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.03      0.04      0.04        67\n",
      "          61       0.02      0.07      0.03       195\n",
      "          62       0.06      0.02      0.03       833\n",
      "          63       0.34      0.22      0.27      1081\n",
      "          64       0.00      0.00      0.00        23\n",
      "          65       0.00      0.00      0.00        33\n",
      "          67       0.00      0.00      0.00        11\n",
      "          68       0.00      0.00      0.00         0\n",
      "          69       0.00      0.00      0.00         4\n",
      "          70       0.00      0.00      0.00         4\n",
      "          71       0.00      0.00      0.00        70\n",
      "          72       0.01      0.01      0.01       118\n",
      "          73       0.00      0.00      0.00        15\n",
      "          74       0.01      0.01      0.01       152\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        41\n",
      "          77       0.00      0.00      0.00         5\n",
      "          78       0.00      0.00      0.00        17\n",
      "          79       0.00      0.00      0.00        16\n",
      "          80       0.02      0.03      0.02       328\n",
      "          81       0.01      0.01      0.01       281\n",
      "          82       0.00      0.00      0.00       112\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00        26\n",
      "          85       0.00      0.00      0.00         0\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00       289\n",
      "          88       0.00      0.00      0.00       135\n",
      "          89       0.00      0.00      0.00        81\n",
      "          90       0.00      0.00      0.00         0\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         0\n",
      "          93       0.00      0.00      0.00        76\n",
      "          94       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00        39\n",
      "          97       0.00      0.00      0.00         9\n",
      "          98       0.00      0.00      0.00       142\n",
      "          99       0.00      0.00      0.00        22\n",
      "         100       0.00      0.00      0.00        47\n",
      "         101       0.00      0.00      0.00        54\n",
      "         102       0.00      0.00      0.00         1\n",
      "         103       0.39      0.43      0.41       313\n",
      "         104       0.01      0.02      0.01        46\n",
      "         105       0.03      0.11      0.04         9\n",
      "         106       0.00      0.00      0.00         1\n",
      "         107       0.02      0.00      0.01      1047\n",
      "         108       0.00      0.00      0.00         0\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         4\n",
      "         111       0.00      0.00      0.00        52\n",
      "         112       0.01      0.11      0.01         9\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         5\n",
      "         115       0.10      0.12      0.11        58\n",
      "         116       0.01      0.00      0.00       281\n",
      "         117       0.06      0.02      0.03       237\n",
      "         118       0.00      0.00      0.00        10\n",
      "         119       0.00      0.00      0.00        26\n",
      "         120       0.01      0.01      0.01       152\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00        27\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.26      0.32      0.28       107\n",
      "         125       0.00      0.00      0.00         2\n",
      "         126       0.04      0.06      0.05        86\n",
      "         127       0.15      0.07      0.09       591\n",
      "         128       0.05      0.05      0.05        64\n",
      "         129       0.00      0.00      0.00        23\n",
      "         131       0.00      0.00      0.00        42\n",
      "         132       0.02      0.01      0.01       411\n",
      "         133       0.00      0.00      0.00       197\n",
      "         134       0.00      0.00      0.00        44\n",
      "         135       0.00      0.00      0.00        76\n",
      "         136       0.05      0.01      0.02       641\n",
      "         137       0.67      0.85      0.75       263\n",
      "         138       0.08      0.18      0.11        33\n",
      "         139       0.01      0.03      0.02        40\n",
      "         140       0.18      0.02      0.04      1889\n",
      "         141       0.00      0.00      0.00         9\n",
      "         142       0.00      0.00      0.00        20\n",
      "         143       0.18      0.18      0.18       150\n",
      "         144       0.09      0.01      0.02      1700\n",
      "         145       0.02      0.02      0.02       149\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.18      0.09      0.12      8135\n",
      "         150       0.17      0.57      0.26     11851\n",
      "         151       0.01      0.08      0.01        13\n",
      "         152       0.33      0.21      0.26       305\n",
      "         153       0.12      0.02      0.03      4730\n",
      "         154       0.38      0.04      0.07      5151\n",
      "         155       0.01      0.03      0.02        34\n",
      "         156       0.00      0.00      0.00        55\n",
      "         157       0.49      0.37      0.42      2714\n",
      "         158       0.00      0.00      0.00        14\n",
      "         159       0.04      0.03      0.03       213\n",
      "         160       0.00      0.00      0.00       156\n",
      "         161       0.01      0.00      0.01      1081\n",
      "         162       0.03      0.01      0.02       605\n",
      "         163       0.00      0.00      0.00        15\n",
      "         164       0.01      0.01      0.01       691\n",
      "         165       0.00      0.00      0.00         7\n",
      "         166       0.00      0.00      0.00       324\n",
      "         167       0.00      0.00      0.00        85\n",
      "         168       0.00      0.00      0.00        71\n",
      "         169       0.01      0.00      0.01       257\n",
      "         170       0.00      0.00      0.00        77\n",
      "         171       0.01      0.02      0.02        95\n",
      "         172       0.00      0.00      0.00       135\n",
      "         173       0.00      0.00      0.00       144\n",
      "         174       0.25      0.13      0.17      1707\n",
      "         175       0.00      0.00      0.00         2\n",
      "         176       0.00      0.00      0.00        17\n",
      "         177       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.14     78886\n",
      "   macro avg       0.04      0.03      0.03     78886\n",
      "weighted avg       0.15      0.14      0.10     78886\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kzaremski/Library/Mobile Documents/com~apple~CloudDocs/School/CS 3120 001 - Machine Learning/CS 3120 Project/denver-crime-heatmap/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "# Encode the target variable\n",
    "encoder = LabelEncoder()\n",
    "df['OFFENSE_TYPE_ID'] = encoder.fit_transform(df['OFFENSE_TYPE_ID'])\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Remove rare classes with only 1 instance\n",
    "class_counts = y.value_counts()\n",
    "rare_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "# Filter out the rare classes from the dataset\n",
    "filtered_df = df[~df['OFFENSE_TYPE_ID'].isin(rare_classes)]\n",
    "\n",
    "# Update X and y after removing rare classes\n",
    "X = filtered_df.drop('OFFENSE_TYPE_ID', axis=1)\n",
    "y = filtered_df['OFFENSE_TYPE_ID']\n",
    "\n",
    "# Train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Ensure no class is left with fewer than 2 members in either train or test\n",
    "train_class_counts = y_train.value_counts()\n",
    "test_class_counts = y_test.value_counts()\n",
    "\n",
    "# Print out the counts for train and test to debug\n",
    "print(\"Train Class Distribution:\\n\", train_class_counts)\n",
    "print(\"Test Class Distribution:\\n\", test_class_counts)\n",
    "\n",
    "# Check if any class is left with 1 sample in the train set\n",
    "if any(train_class_counts < 2):\n",
    "    print(\"Some classes in the train set have less than 2 samples. Consider further reducing or combining classes.\")\n",
    "else:\n",
    "    # Initialize and train the model\n",
    "    model = HistGradientBoostingClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    # If you want to decode the predictions back to the original labels:\n",
    "    decoded_predictions = encoder.inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Likelihood Model (Gradient Boosting Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.1193554506525847\n"
     ]
    }
   ],
   "source": [
    "# Get a copy of the initial data frame\n",
    "df = original_df.copy()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming df is your original dataframe\n",
    "# Group by grid cell, day of year, and hour to count crimes\n",
    "crime_counts = df.groupby(['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR']).size().reset_index(name='CRIME_COUNT')\n",
    "\n",
    "# Features and target\n",
    "X = crime_counts[['X_BLOCK', 'Y_BLOCK', 'DAY_OF_YEAR', 'HOUR']]\n",
    "y = crime_counts['CRIME_COUNT']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = HistGradientBoostingRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Thank you for taking the time to review my project! Moving forward, I plan to integrate OpenStreetMap (OSM) to enhance the location-based features. Additionally, I will be working on improving the model's accuracy by conducting a hyperparameter grid search with cross-validation. Finally, I’ll focus on finishing the front-end development of the app to ensure a smooth and user-friendly experience. I look forward to any further feedback and continuing to improve the project!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
